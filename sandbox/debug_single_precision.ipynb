{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8141d2-aa9b-4b75-adb4-d9d8cfe91386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfranz/research/hepfile/src/hepfile/write.py:564: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if group == \"_SINGLETONS_GROUP_\" and dataset is not \"COUNTER\":\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import hepfile as hf\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db93f3be-cdb9-4d8c-ad3d-0fd551bb4400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def awkward_to_hepfile(ak_array:ak.Record, outfile:str=None, write_hepfile:bool=True, **kwargs) -> dict:\n",
    "    '''\n",
    "    Converts a dictionary of awkward arrays to a hepfile\n",
    "\n",
    "    Args:\n",
    "        ak_array (Awkward Array): dictionary of Awkward Arrays to write to a hepfile\n",
    "        outfile (str): path to write output hdf5 file to\n",
    "        write_hepfile (bool): if True, writes data to outfile. If False, just converts to hepfile format and returns\n",
    "        **kwargs (None): Passed to `hepfile.write.write_to_file`\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of hepfile data\n",
    "    '''\n",
    "\n",
    "    # perform IO checks\n",
    "\n",
    "    hf.awkward_tools._is_valid_awkward(ak_array)\n",
    "    \n",
    "    if write_hepfile == True and outfile is None:\n",
    "        raise IOError('Please provide an outfile path if write_hepfile=True!')\n",
    "\n",
    "    if write_hepfile == False and outfile is not None:\n",
    "        raise Warning('You set write_hepfile to False but provided an output file path. This output file path will not be used!')\n",
    "    \n",
    "    data = hf.initialize()\n",
    "    singleton = False\n",
    "\n",
    "    for group in ak_array.fields:\n",
    "        \n",
    "        counter = f'n{group}'\n",
    "        counter_key = f'{group}/{counter}'\n",
    "        \n",
    "        if len(ak_array[group].fields) == 0:\n",
    "            singleton = True\n",
    "            \n",
    "            dtype = hf.awkward_tools._get_awkward_type(ak_array[group])\n",
    "            hf.create_dataset(data, group, dtype=dtype)\n",
    "\n",
    "            data[group] = ak_array[group]\n",
    "            continue\n",
    "    \n",
    "        hf.create_group(data, group, counter=counter)\n",
    "        for ii, dataset in enumerate(ak_array[group].fields):\n",
    "            \n",
    "            dtype = hf.awkward_tools._get_awkward_type(ak_array[group][dataset])\n",
    "            hf.create_dataset(data, dataset, group=group, dtype=dtype)\n",
    "            \n",
    "            # check if dataset name has /'s in it\n",
    "            if dataset.find('/') >= 0:\n",
    "                dataset_name = dataset.replace('/', '-')\n",
    "            else:\n",
    "                dataset_name = dataset\n",
    "                \n",
    "            name = f'{group}/{dataset_name}'\n",
    "            for data_subset in ak_array[group][dataset]:\n",
    "                data[name].append(data_subset)\n",
    "                if ii == 0:\n",
    "                    data[counter_key].append(len(data_subset))            \n",
    "            \n",
    "            data[name] = ak.flatten(ak.Array(data[name]))\n",
    "    \n",
    "        data[counter_key] = ak.Array(data[counter_key])\n",
    "    \n",
    "    if len(data['_GROUPS_']['_SINGLETONS_GROUP_']) > 1:\n",
    "        data['_SINGLETONS_GROUP_/COUNTER'] = [1]*len(data[data['_GROUPS_']['_SINGLETONS_GROUP_'][1]])\n",
    "\n",
    "    if write_hepfile:\n",
    "        print(\"Writing the hdf5 file from the awkward array...\")\n",
    "        hdfile = hf.write_to_file(outfile,data)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d57c38-4a91-4b13-9312-79c3ac3d9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dictionary\n",
    "d = [\n",
    "    {\n",
    "    'jet': {\n",
    "        'px': [1,2,3],\n",
    "        'py': [1,2,3]\n",
    "     },\n",
    "    'muons': {\n",
    "        'px': [1,2,3],\n",
    "        'py': [1,2,3]\n",
    "     },\n",
    "    'other': 'this'\n",
    "    },\n",
    "    {\n",
    "    'jet': {\n",
    "        'px': [3,4,6,7],\n",
    "        'py': [3,4,6,7]\n",
    "     },\n",
    "    'muons': {\n",
    "        'px': [3,4,6,7],\n",
    "        'py': [3,4,6,7],\n",
    "        },\n",
    "    'other': 'this'\n",
    "    }\n",
    "]\n",
    "\n",
    "awk = ak.Array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80a5985-9c58-4321-a41c-993d52f82bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding group \u001b[1mjet\u001b[0m\n",
      "Adding a counter for \u001b[1mjet\u001b[0m as \u001b[1mnjet\u001b[0m\n",
      "Adding dataset \u001b[1mpx\u001b[0m to the dictionary under group \u001b[1mjet\u001b[0m.\n",
      "Adding dataset \u001b[1mpy\u001b[0m to the dictionary under group \u001b[1mjet\u001b[0m.\n",
      "Adding group \u001b[1mmuons\u001b[0m\n",
      "Adding a counter for \u001b[1mmuons\u001b[0m as \u001b[1mnmuons\u001b[0m\n",
      "Adding dataset \u001b[1mpx\u001b[0m to the dictionary under group \u001b[1mmuons\u001b[0m.\n",
      "Adding dataset \u001b[1mpy\u001b[0m to the dictionary under group \u001b[1mmuons\u001b[0m.\n",
      "Adding dataset \u001b[1mother\u001b[0m to the dictionary as a SINGLETON.\n",
      "Writing the hdf5 file from the awkward array...\n",
      "{'_SINGLETONS_GROUP_/COUNTER': <class 'int'>, 'jet/njet': <class 'int'>, 'jet/px': <class 'numpy.int64'>, 'jet/py': <class 'numpy.int64'>, 'muons/nmuons': <class 'int'>, 'muons/px': <class 'numpy.int64'>, 'muons/py': <class 'numpy.int64'>, 'other': <class 'str'>}\n",
      "_SINGLETONS_GROUP_/COUNTER       has 2            entries\n",
      "jet/njet                         has 2            entries\n",
      "muons/nmuons                     has 2            entries\n",
      "Metadata added\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_GROUPS_': {'_SINGLETONS_GROUP_': ['COUNTER', 'other'],\n",
       "  'jet': ['njet', 'px', 'py'],\n",
       "  'muons': ['nmuons', 'px', 'py']},\n",
       " '_MAP_DATASETS_TO_COUNTERS_': {'_SINGLETONS_GROUP_': '_SINGLETONS_GROUP_/COUNTER',\n",
       "  'jet': 'jet/njet',\n",
       "  'jet/px': 'jet/njet',\n",
       "  'jet/py': 'jet/njet',\n",
       "  'muons': 'muons/nmuons',\n",
       "  'muons/px': 'muons/nmuons',\n",
       "  'muons/py': 'muons/nmuons',\n",
       "  'other': '_SINGLETONS_GROUP_/COUNTER'},\n",
       " '_LIST_OF_COUNTERS_': ['_SINGLETONS_GROUP_/COUNTER',\n",
       "  'jet/njet',\n",
       "  'muons/nmuons'],\n",
       " '_SINGLETONS_GROUP_/COUNTER': [1, 1],\n",
       " '_MAP_DATASETS_TO_DATA_TYPES_': {'_SINGLETONS_GROUP_/COUNTER': int,\n",
       "  'jet/njet': int,\n",
       "  'jet/px': numpy.int64,\n",
       "  'jet/py': numpy.int64,\n",
       "  'muons/nmuons': int,\n",
       "  'muons/px': numpy.int64,\n",
       "  'muons/py': numpy.int64,\n",
       "  'other': str},\n",
       " '_PROTECTED_NAMES_': ['_PROTECTED_NAMES_',\n",
       "  '_GROUPS_',\n",
       "  '_MAP_DATASETS_TO_COUNTERS_',\n",
       "  '_MAP_DATASETS_TO_DATA_TYPES__LIST_OF_COUNTERS_',\n",
       "  '_SINGLETONS_GROUP_/COUNTER'],\n",
       " 'jet/njet': <Array [3, 4] type='2 * int64'>,\n",
       " 'jet/px': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'jet/py': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'muons/nmuons': <Array [3, 4] type='2 * int64'>,\n",
       " 'muons/px': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'muons/py': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'other': <Array ['this', 'this'] type='2 * string'>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'test.h5'\n",
    "awkward_to_hepfile(awk, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cbf318-d696-41d0-9bff-ba7ec2379bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
