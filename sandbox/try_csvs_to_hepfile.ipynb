{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "625365c5-6ba4-474a-8927-85473ac2908a",
   "metadata": {},
   "source": [
    "# CSVS to Hepfile\n",
    "Imagine we have a database like structure with multiple csvs all connected by a common ID. See the household exmaple here: https://hepfile.readthedocs.io/en/latest/fundamentals.html#a-toy-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3bfb6f-e279-4d98-b06b-1b61db157237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "import hepfile as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95bdabd3-31a6-4aa1-9989-9d5f4a514ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Slashes / are not allowed in dataset names\n",
      "Replacing / with - in dataset name Highest degree/grade\n",
      "The new name will be Highest degree-grade\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Slashes / are not allowed in dataset names\n",
      "Replacing / with - in dataset name Gas/electric/human powered\n",
      "The new name will be Gas-electric-human powered\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Slashes / are not allowed in dataset names\n",
      "Replacing / with - in dataset name House/apartment/condo\n",
      "The new name will be House-apartment-condo\n",
      "----------------------------------------------------\n",
      "Writing the hdf5 file from the awkward array...\n",
      "Metadata added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfranz/research/hepfile/src/hepfile/write.py:658: UserWarning: Residences/nResidences and _SINGLETONS_GROUP_/COUNTER have differing numbers of entries!\n",
      "  warnings.warn(f\"{countername} and {prevcounter} have differing numbers of entries!\")\n",
      "/home/nfranz/research/hepfile/src/hepfile/write.py:658: UserWarning: People/nPeople and Residences/nResidences have differing numbers of entries!\n",
      "  warnings.warn(f\"{countername} and {prevcounter} have differing numbers of entries!\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datapath = os.path.join('/', 'home', 'nfranz', 'research', 'hepfile', 'docs', 'example_nb', '*.csv')\n",
    "files = glob.glob(datapath)\n",
    "common_key = 'Household ID'\n",
    "group_names = ['Residences', 'People', 'Vehicles']\n",
    "awk = hf.csv_tools.csv_to_hepfile(files, common_key, outfile='test-csv.h5', group_names=group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2132ac-809e-4e9e-828c-2cd62b9e2758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the indices...\n",
      "\n",
      "Built the indices!\n",
      "Data is read in and input file is closed.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dict of arrays in ak.Array constructor must have arrays of equal length (3 vs 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data, _ \u001b[38;5;241m=\u001b[39m \u001b[43mhf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest-csv.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_awkward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m data\n",
      "File \u001b[0;32m~/research/hepfile/src/hepfile/read.py:336\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, verbose, desired_groups, subset, return_awkward)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_awkward:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mawkward_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hepfile_to_awkward\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhepfile_to_awkward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, bucket\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, bucket\n",
      "File \u001b[0;32m~/research/hepfile/src/hepfile/awkward_tools.py:60\u001b[0m, in \u001b[0;36mhepfile_to_awkward\u001b[0;34m(data, groups, datasets)\u001b[0m\n\u001b[1;32m     57\u001b[0m             ak_arrays[group] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     58\u001b[0m         ak_arrays[group][dset] \u001b[38;5;241m=\u001b[39m ak_array\n\u001b[0;32m---> 60\u001b[0m awk \u001b[38;5;241m=\u001b[39m \u001b[43mak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mak_arrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     _is_valid_awkward(awk)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/awkward/highlevel.py:204\u001b[0m, in \u001b[0;36mArray.__init__\u001b[0;34m(self, data, behavior, with_name, check_valid, backend)\u001b[0m\n\u001b[1;32m    202\u001b[0m             length \u001b[38;5;241m=\u001b[39m contents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m length \u001b[38;5;241m!=\u001b[39m contents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m--> 204\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    205\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict of arrays in ak.Array constructor must have arrays \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof equal length (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(length, contents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlength)\n\u001b[1;32m    207\u001b[0m             )\n\u001b[1;32m    208\u001b[0m     layout \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39mcontents\u001b[38;5;241m.\u001b[39mRecordArray(contents, fields)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: dict of arrays in ak.Array constructor must have arrays of equal length (3 vs 4)"
     ]
    }
   ],
   "source": [
    "data, _ = hf.load('test-csv.h5', return_awkward=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef809201-b29e-4798-86b9-bbd90eb4f2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
