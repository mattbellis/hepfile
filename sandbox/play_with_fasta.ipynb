{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6279494b-0a8b-40f9-a940-97db0e8a3a0f",
   "metadata": {},
   "source": [
    "# Play with FASTA Files and Hepfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e86404-8f40-48ea-b657-0ad75353408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hepfile as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b6dba-fa12-4249-86bf-4225ee93025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(filepath:str) -> list[str]:\n",
    "    '''\n",
    "    Function to read in a fasta file and return a list of the nucleotide sequences\n",
    "    \n",
    "    Args:\n",
    "        filepath [str]: path to the fasta file\n",
    "        \n",
    "    Returns:\n",
    "        list of nucleotide sequences to be parsed\n",
    "    '''\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = [line.replace('\\n', '').strip() for line in f.readlines()]\n",
    "        idxs = [idx for idx, line in enumerate(lines) if line[0] == '>']\n",
    "                \n",
    "    split_fasta = []\n",
    "    for ii in range(len(idxs)):\n",
    "        idx1 = idxs[ii]\n",
    "        if ii == len(idxs)-1:\n",
    "            idx2 = -1\n",
    "        else:\n",
    "            idx2 = idxs[ii+1]\n",
    "        \n",
    "        split_fasta.append(lines[idx1:idx2])\n",
    "        \n",
    "    return split_fasta\n",
    "\n",
    "def parse_sequence(seq:str) -> dict:\n",
    "    '''\n",
    "    Parses a sequence and returns a dictionary of the information\n",
    "    \n",
    "    Args:\n",
    "        seq (str): sequence in fasta format\n",
    "    \n",
    "    Returns:\n",
    "        dictionary of sequence\n",
    "    '''\n",
    "    \n",
    "    # first deal with the metadata\n",
    "    meta = seq[0].split()\n",
    "    name = meta[0][1:]\n",
    "    descr = meta[1:]\n",
    "    \n",
    "    # then concatenate the rest of the data\n",
    "    data = ''.join(seq[1:])\n",
    "    \n",
    "    # pack this all into a dictionary\n",
    "    all_data = {'name': name, 'meta':descr, 'data':list(data)}\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd52602-57e7-49c8-a2ee-389f76ef24ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/nfranz/research/hepfile/docs/example_nb/test.fasta'\n",
    "split = read_fasta(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a668d0f4-8378-48a3-bf59-74ec808fc51b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entering the data as singletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90f17e-457b-457b-9ff5-1a7504381771",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for seq in split:\n",
    "    data.append(parse_sequence(seq))\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ea07b-6dca-42f3-af0c-50621d329e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "awk = hf.dict_tools.dictlike_to_hepfile(data, 'out-fasta.h5', write_hepfile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e8a66-1359-4370-afdc-bc7c2b4e3ee0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Examples using the hepfile structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e4be7-64b1-4280-a9be-bf08bee477d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the data names\n",
    "awk.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e35e97-30c4-4812-b303-430fa3b2640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the data flattened\n",
    "import awkward as ak\n",
    "ak.flatten(awk.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd0fad-3f78-4f21-8f55-1a8f5211b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information corresponding to 'crab_anapl'\n",
    "anapl = awk[awk.name == 'crab_anapl']\n",
    "anapl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc012f2-b103-45a4-8253-82ca57bf1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just the crab_anapl data\n",
    "anapl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a22320-ca4f-4f30-9ba1-f8ded3d54225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just the crab_anapl metadata\n",
    "anapl.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb920e06-feb3-4abd-9429-95acdb0ce2a3",
   "metadata": {},
   "source": [
    "## Entering the data using groups and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0eae36-6957-45e1-8f8f-870d611caaae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hepfile = hf.initialize()\n",
    "\n",
    "for_hepfile = []\n",
    "for seq in split:\n",
    "    for_hepfile.append(parse_sequence(seq))\n",
    "\n",
    "for d in for_hepfile:\n",
    "    \n",
    "    group = d['name']\n",
    "    \n",
    "    # create the group and add metadata for that group\n",
    "    hf.create_group(hepfile, group, counter=f'n_{group}')\n",
    "    hf.add_group_meta(hepfile, group, d['meta'])\n",
    "    \n",
    "    # create a dataset underneath that group\n",
    "    hf.create_dataset(hepfile, 'sequence', group=group, dtype=str)\n",
    "    \n",
    "bucket = hf.create_single_bucket(hepfile)\n",
    "for d in for_hepfile:\n",
    "    group = d['name']\n",
    "    bucket[f'{group}/sequence'] = d['data']\n",
    "\n",
    "return_value = hf.pack(hepfile,bucket,STRICT_CHECKING=True,verbose=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61d88c-aad3-43a7-a157-c12167e78e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'test-fasta-out.h5'\n",
    "hf.write_to_file(filepath, hepfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2edb7-2e95-4612-b703-2b95c6d04ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hepfile['_GROUPS_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345e52b-36aa-430a-b164-38b7aa1647f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta, bucket = hf.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c06a7f-55e5-4b0c-8969-91feea234f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f617d62-df1b-4ccf-a668-92f4e80dea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4960db3-d48e-41a0-8b3d-97e428d52a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
