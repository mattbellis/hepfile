{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "import hepfile\n",
    "\n",
    "import uproot\n",
    "\n",
    "import time\n",
    "\n",
    "print(ak.__version__)\n",
    "print(uproot.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down load a file for us to play with\n",
    "!curl http://opendata.cern.ch/record/12361/files/SMHiggsToZZTo4L.root --output SMHiggsToZZTo4L.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all for demonstration purposes, to show people how this type of\n",
    "# writing could be done. \n",
    "# But of course people could just create their own awkward arrays.\n",
    "\n",
    "f = uproot.open('SMHiggsToZZTo4L.root')\n",
    "\n",
    "events = f['Events']\n",
    "\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da27f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's in this file? \n",
    "events.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out these types and their sizes\n",
    "\n",
    "print(type(events['Muon_pt'].array()))\n",
    "print()\n",
    "\n",
    "# Number of events\n",
    "print(ak.num(events['Muon_pt'].array(),axis=0))\n",
    "\n",
    "# Number of muons in each event\n",
    "print(ak.num(events['Muon_pt'].array(),axis=1))\n",
    "\n",
    "# Number of muons in total\n",
    "print(ak.sum(ak.num(events['Muon_pt'].array(),axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While not all the entries in the ROOT file naturally lend themselves to \n",
    "# group/dataset breakdowns, some do. Let's find those \"automatically\", \n",
    "# just to make it easier to write them to the hepfile.\n",
    "\n",
    "# Find groups\n",
    "def make_groups_and_datasets(fields):\n",
    "    \n",
    "    groups = {}\n",
    "    \n",
    "    for field in fields:\n",
    "        if field.find('_')>=0:\n",
    "            \n",
    "            # Do this in case there is more than one underscore\n",
    "            idx = field.find('_')\n",
    "            \n",
    "            #print(field)\n",
    "            grp = field[0:idx]\n",
    "            dset = field[idx+1:]\n",
    "            \n",
    "            if grp not in groups.keys():\n",
    "                groups[grp] = [[field,dset]]\n",
    "            else:\n",
    "                groups[grp].append([field,dset])\n",
    "    \n",
    "    return groups\n",
    "\n",
    "\n",
    "############################################################\n",
    "\n",
    "groupings = make_groups_and_datasets(events.keys())\n",
    "\n",
    "# Groupings gives us a nice mapping of the names from the ROOT file\n",
    "# to how we're going to store them in our hepfile as \n",
    "# group/datasets\n",
    "\n",
    "print(groupings)\n",
    "print()\n",
    "print(groupings['Muon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some others. THese will be SINGLETONS that we pass in separately.\n",
    "'run',\n",
    "'luminosityBlock',\n",
    "'event',\n",
    "\n",
    "print(events['run'].array())\n",
    "print(events['luminosityBlock'].array())\n",
    "print(events['event'].array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b057d-8669-43bf-9b3c-b470b7fa5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_awkward_type(ak_array: ak.Record) -> type:\n",
    "    try:\n",
    "        if isinstance(ak_array[0], (ak.Record, ak.Array)):\n",
    "            arr = ak_array\n",
    "            #import pdb; pdb.set_trace()\n",
    "            \n",
    "            #print(ak_array.type.content)\n",
    "            \n",
    "            type_str = ak_array.type.content            \n",
    "            \n",
    "            if isinstance(type_str, ak.types.NumpyType):\n",
    "                dtype = type_str.primitive\n",
    "            else:\n",
    "                dtype = str(type_str).rsplit(\"*\", maxsplit=1)[-1].strip()\n",
    "            \n",
    "        else:\n",
    "            arr = np.array(ak_array)\n",
    "            dtype = arr.dtype\n",
    "\n",
    "        if dtype == \"string\":\n",
    "            dtype = np.dtype(\"<U1\")\n",
    "\n",
    "        np_dtype = np.dtype(dtype)\n",
    "        if np_dtype.char == \"U\":\n",
    "            np_dtype = str\n",
    "\n",
    "    except Exception as exc:\n",
    "        raise IOError(\"Cannot convert input value to a numpy data type!\") from exc\n",
    "\n",
    "    return np_dtype\n",
    "\n",
    "# Try it out\n",
    "print(_get_awkward_type(events['Muon_pt'].array()))\n",
    "print(_get_awkward_type(events['MET_pt'].array()))\n",
    "print(_get_awkward_type(events['run'].array()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6647b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I changed the name of this function to pack multiple awkward arrays.\n",
    "# I agree with you that we should probably also have a function that packs\n",
    "# single awkward arrays that gets called by this function.\n",
    "\n",
    "# d = data dictionary, maybe we have a version of this that automatically\n",
    "# creates the dictionary and returns it?\n",
    "\n",
    "# arr = dictionary of awkward arrays and keys to use as names for the dataset\n",
    "\n",
    "# group_name = group the dataset will belong to\n",
    "\n",
    "# Right now, I am creating a counter \"n{group_name}\", is that what we want?\n",
    "# Or should we allow the user to pass in the counter name, like when\n",
    "# create_group is called?\n",
    "#\n",
    "# Right now, it creates the group each time this function is called\n",
    "# We should have it check to see if the group is already there and if so, \n",
    "# don't add it again.\n",
    "\n",
    "def pack_multiple_awkward_arrays(d, arr, group_name=None):\n",
    "    \n",
    "    # If the user passed in a group, then the datasets will \n",
    "    # be under that group\n",
    "\n",
    "    # If no groupname is passed in, we will assume these are singleton datasets    \n",
    "    if group_name is not None:\n",
    "        counter = f\"n{group_name}\"\n",
    "        d['_GROUPS_'][group_name] = [counter]\n",
    "\n",
    "        # We will use this name for the counter later\n",
    "        counter = f\"{group_name}/n{group_name}\"\n",
    "        d['_MAP_DATASETS_TO_DATA_TYPES_'][counter] = int\n",
    "\n",
    "        d['_MAP_DATASETS_TO_COUNTERS_'][group_name] = counter\n",
    "        d['_LIST_OF_COUNTERS_'].append(counter)\n",
    "    else:\n",
    "        counter = '_SINGLETONS_GROUP_/COUNTER'\n",
    "        \n",
    "\n",
    "    # Loop over the dictionary that is passed in\n",
    "    for field in arr.keys():\n",
    "        # build a name for the hepfile entry\n",
    "        dataset_name = f\"{group_name}/{field}\"\n",
    "        \n",
    "        # If there is no group name, it is a SINGLETON\n",
    "        if group_name is None:\n",
    "            dataset_name = f\"{field}\"\n",
    "        \n",
    "        #print(field)\n",
    "        \n",
    "        print(dataset_name)\n",
    "        \n",
    "        # Get the values\n",
    "        x = arr[field]\n",
    "        \n",
    "        # For debugging\n",
    "        #print(f\"\\t{v}   {x.ndim}\")\n",
    "        \n",
    "        # Tells us if this is jagged or not\n",
    "        dtype = _get_awkward_type(x)\n",
    "        \n",
    "        if x.ndim==1:\n",
    "\n",
    "            # Get the datatpe before we flatten it\n",
    "            dtype = _get_awkward_type(x)\n",
    "            \n",
    "            x = ak.to_numpy(x)\n",
    "            num = np.ones(len(x),dtype=int) # This is repeated, should we only do it once?\n",
    "        \n",
    "        else:\n",
    "\n",
    "            # Get the datatpe before we flatten it\n",
    "            dtype = _get_awkward_type(x)\n",
    "            \n",
    "            # This saves the counter as int64, taking up a bit more space\n",
    "            # Probably minimal though. \n",
    "            #num = ak.num(x)\n",
    "            # This saves the counter as int32\n",
    "            num = ak.to_numpy(ak.num(x)).astype(np.int32)\n",
    "\n",
    "            x = ak.flatten(x).to_numpy()\n",
    "            \n",
    "        d[dataset_name] = x\n",
    "        \n",
    "        #print(dtype_dict[dtype])\n",
    "        \n",
    "        # Not a SINGLETON, the user has passed in a groupname\n",
    "        if group_name is not None:\n",
    "            d['_MAP_DATASETS_TO_DATA_TYPES_'][dataset_name] = dtype\n",
    "            d['_MAP_DATASETS_TO_COUNTERS_'][dataset_name] = counter\n",
    "            d['_GROUPS_'][group_name].append(field)\n",
    "        # If it is a SINGLETON\n",
    "        else:\n",
    "            d['_MAP_DATASETS_TO_DATA_TYPES_'][dataset_name] = dtype\n",
    "            d['_MAP_DATASETS_TO_COUNTERS_'][dataset_name] = '_SINGLETONS_GROUP_/COUNTER'\n",
    "            d['_GROUPS_']['_SINGLETONS_GROUP_'].append(dataset_name)        \n",
    "\n",
    "    d[counter] = num\n",
    "    # We don't need to return the dictionary because in python\n",
    "    # dictionaries are mutable. The dictionary in the function points to \n",
    "    # the same object outside of the function.\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# Here's how we call it. Though maybe we have an option to have\n",
    "# the data dictionary created inside the function? \n",
    "\n",
    "# Initialize the data dictionary\n",
    "data = hepfile.initialize()\n",
    "\n",
    "# Pack these groups of awkward arrays\n",
    "\n",
    "# This is what it would look like \"by hand\"\n",
    "# A dictionary with the name of the dataset as it is to appear inside the hepfile\n",
    "# and then the actual awkward array (not just the Branch object returned by uproot)\n",
    "#ak_arrays = {'pt': events['Muon_pt'].array(), 'eta': events['Muon_eta'].array(), 'phi':events['Muon_phi'].array(), }\n",
    "\n",
    "# Here I'm packing all the data that are groups/datasets\n",
    "for groups_to_write in ['Muon', 'Electron', 'MET', 'PV']:\n",
    "    ak_arrays = {}\n",
    "    for grouping in groupings[groups_to_write]:\n",
    "        #print(grouping)\n",
    "        ak_arrays[grouping[1]] = events[grouping[0]].array()\n",
    "    \n",
    "    # For debugging\n",
    "    #print(ak_arrays)\n",
    "    \n",
    "    pack_multiple_awkward_arrays(data, ak_arrays, group_name=groups_to_write)\n",
    "\n",
    "# Now the SINGLETONS\n",
    "ak_arrays = {\"run\":events['run'].array(), \\\n",
    "             \"luminosityBlock\":events['luminosityBlock'].array(), \\\n",
    "             \"event\":events['event'].array()}\n",
    "\n",
    "# Note that there is no group name passed in. \n",
    "pack_multiple_awkward_arrays(data, ak_arrays)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cd52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to see what the data dictionary looks like\n",
    "#data\n",
    "\n",
    "print(data['_GROUPS_']['_SINGLETONS_GROUP_'])\n",
    "print()\n",
    "\n",
    "print(data['_MAP_DATASETS_TO_COUNTERS_'])\n",
    "print()\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba272902",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write it!\n",
    "\n",
    "# Try it with no compression\n",
    "start = time.time()\n",
    "hepfile.write_to_file('awkward_write_test.h5', data, verbose=False)\n",
    "dt_no_compression = time.time() - start\n",
    "\n",
    "# Try it with compression!\n",
    "start = time.time()\n",
    "hepfile.write_to_file('awkward_write_test_COMP_gzip_OPT_9.h5', data, verbose=False, comp_type=\"gzip\", comp_opts=9)\n",
    "dt_with_compression = time.time() - start\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(f\"Time to write uncompressed: {dt_no_compression}\")\n",
    "print(f\"Time to write   compressed: {dt_with_compression}\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Check out the sizes of the files!\n",
    "\n",
    "!ls -ltr SMHiggsToZZTo4L.root\n",
    "!ls -ltr awkward_write_test.h5\n",
    "!ls -ltr awkward_write_test_COMP_gzip_OPT_9.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,bucket = hepfile.load('awkward_write_test_COMP_gzip_OPT_9.h5')\n",
    "\n",
    "#data,bucket = hepfile.load('awkward_write_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2213c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Muon/nMuon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adfa207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data['Muon/pt']))\n",
    "print(type(data['Muon/pt'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e39a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['Muon/pt'].astype(np.float32)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccef665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ddcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['_MAP_DATASETS_TO_DATA_TYPES_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6645da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['_GROUPS_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb217dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ak.to_numpy(ak.flatten(events['Muon_pt'].array()))\n",
    "\n",
    "type(x)\n",
    "type(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events['Muon_pt'].array()\n",
    "\n",
    "xnum = ak.num(x)\n",
    "\n",
    "print(type(xnum))\n",
    "print(type(xnum[0]))\n",
    "\n",
    "print(xnum)\n",
    "\n",
    "print(xnum[0])\n",
    "\n",
    "print(type(ak.to_numpy(xnum)[0]))\n",
    "print(type(ak.to_numpy(xnum).astype(np.int32)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c90f74",
   "metadata": {},
   "source": [
    "# Scratch code\n",
    "\n",
    "Just a bunch of test code when I was trying to figure this all out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a75c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "groups_to_datasets = {}\n",
    "\n",
    "counters = []\n",
    "\n",
    "for field in events.fields:\n",
    "    \n",
    "    print(field)\n",
    "    \n",
    "    d[field] = []\n",
    "    groups_to_datasets[field] = []\n",
    "    \n",
    "    counters.append(f'n{field}')\n",
    "    \n",
    "    for v in events[field].fields:\n",
    "        groups_to_datasets[field].append(v)\n",
    "        \n",
    "        key = f\"{field}/{v}\"\n",
    "        \n",
    "        x = events[field][v]\n",
    "        \n",
    "        #print(v)\n",
    "        \n",
    "        print(f\"\\t{v}   {x.ndim}\")\n",
    "        \n",
    "        if x.ndim==1:\n",
    "            dtype = x.layout.format\n",
    "            x = ak.to_numpy(x)\n",
    "\n",
    "        else:\n",
    "            dtype = x.layout.content.format\n",
    "            x = ak.flatten(x).to_numpy()\n",
    "\n",
    "\n",
    "        d[key] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c90f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.num(events['Muon']['pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.luminosityBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2afa89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6be6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events['MET']['pt']\n",
    "\n",
    "print(x.ndim)\n",
    "print(events['Muon']['pt'].ndim)\n",
    "print(events['MET']['pt'].ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.layout\n",
    "layout = events['Electron']['pt'].layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.content.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events['MET']['pt']\n",
    "\n",
    "x.layout.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events['MET']['pt']\n",
    "\n",
    "x.layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22837e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events['MET']['pt']\n",
    "\n",
    "try:\n",
    "    x = ak.flatten(x)\n",
    "except:\n",
    "    1\n",
    "x = ak.to_numpy(x)\n",
    "\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08038a5",
   "metadata": {},
   "source": [
    "# Testing out the loop way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ed315",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hepfile.initialize()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "hepfile.create_group(data,group_name='muon',counter='nmuon')\n",
    "hepfile.create_dataset(data,group='muon',dset_name=['px','py','pz'],dtype=float)\n",
    "\n",
    "hepfile.create_dataset(data,dset_name=['luminosity_block'],dtype=int)\n",
    "\n",
    "bucket = hepfile.create_single_bucket(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7698db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81775b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nevents = 100\n",
    "\n",
    "for i in range(nevents):\n",
    "    nmuon = np.random.randint(0,5)\n",
    "    bucket['muon/nmuon'] = nmuon\n",
    "    bucket['muon/px'] = np.random.random(nmuon).tolist()\n",
    "    bucket['muon/py'] = np.random.random(nmuon).tolist()\n",
    "    bucket['muon/pz'] = np.random.random(nmuon).tolist()\n",
    "    \n",
    "    bucket['luminosity_block'] = np.random.randint(100,10000)\n",
    "    \n",
    "    hepfile.pack(data,bucket)\n",
    "\n",
    "hepfile.write_to_file('awkward_write_test_LOOP_FILL.h5', data, verbose=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8640bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,bucket = hepfile.load('awkward_write_test_LOOP_FILL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['luminosity_block']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b50fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
