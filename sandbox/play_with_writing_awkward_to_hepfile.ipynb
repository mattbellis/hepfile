{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "import hepfile\n",
    "\n",
    "import uproot\n",
    "\n",
    "import time\n",
    "\n",
    "print(ak.__version__)\n",
    "print(uproot.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down load a file for us to play with\n",
    "!curl http://opendata.cern.ch/record/12361/files/SMHiggsToZZTo4L.root --output SMHiggsToZZTo4L.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all for demonstration purposes, to show people how this type of\n",
    "# writing could be done. \n",
    "# But of course people could just create their own awkward arrays.\n",
    "\n",
    "f = uproot.open('SMHiggsToZZTo4L.root')\n",
    "\n",
    "events = f['Events']\n",
    "\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da27f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's in this file? \n",
    "events.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out these types and their sizes\n",
    "\n",
    "print(type(events['Muon_pt'].array()))\n",
    "print()\n",
    "\n",
    "# Number of events\n",
    "print(ak.num(events['Muon_pt'].array(),axis=0))\n",
    "\n",
    "# Number of muons in each event\n",
    "print(ak.num(events['Muon_pt'].array(),axis=1))\n",
    "\n",
    "# Number of muons in total\n",
    "print(ak.sum(ak.num(events['Muon_pt'].array(),axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While not all the entries in the ROOT file naturally lend themselves to \n",
    "# group/dataset breakdowns, some do. Let's find those \"automatically\", \n",
    "# just to make it easier to write them to the hepfile.\n",
    "\n",
    "# Find groups\n",
    "def make_groups_and_datasets(fields):\n",
    "    \n",
    "    groups = {}\n",
    "    \n",
    "    for field in fields:\n",
    "        if field.find('_')>=0:\n",
    "            \n",
    "            # Do this in case there is more than one underscore\n",
    "            idx = field.find('_')\n",
    "            \n",
    "            #print(field)\n",
    "            grp = field[0:idx]\n",
    "            dset = field[idx+1:]\n",
    "            \n",
    "            if grp not in groups.keys():\n",
    "                groups[grp] = [[field,dset]]\n",
    "            else:\n",
    "                groups[grp].append([field,dset])\n",
    "    \n",
    "    return groups\n",
    "\n",
    "\n",
    "############################################################\n",
    "\n",
    "groupings = make_groups_and_datasets(events.keys())\n",
    "\n",
    "# Groupings gives us a nice mapping of the names from the ROOT file\n",
    "# to how we're going to store them in our hepfile as \n",
    "# group/datasets\n",
    "\n",
    "print(groupings)\n",
    "print()\n",
    "print(groupings['Muon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some others. THese will be SINGLETONS that we pass in separately.\n",
    "'run',\n",
    "'luminosityBlock',\n",
    "'event',\n",
    "\n",
    "print(events['run'].array())\n",
    "print(events['luminosityBlock'].array())\n",
    "print(events['event'].array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b057d-8669-43bf-9b3c-b470b7fa5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_awkward_type(ak_array: ak.Record) -> type:\n",
    "    try:\n",
    "        if isinstance(ak_array[0], (ak.Record, ak.Array)):\n",
    "            arr = ak_array\n",
    "            type_str = ak_array.type.content            \n",
    "            \n",
    "            if isinstance(type_str, ak.types.NumpyType):\n",
    "                dtype = type_str.primitive\n",
    "            else:\n",
    "                dtype = str(type_str).rsplit(\"*\", maxsplit=1)[-1].strip()\n",
    "            \n",
    "        else:\n",
    "            arr = np.array(ak_array)\n",
    "            dtype = arr.dtype\n",
    "\n",
    "        if dtype == \"string\":\n",
    "            dtype = np.dtype(\"<U1\")\n",
    "    \n",
    "        np_dtype = np.dtype(dtype)\n",
    "        if np_dtype.char == \"U\":\n",
    "            np_dtype = str\n",
    "\n",
    "    except Exception as exc:\n",
    "        raise IOError(\"Cannot convert input value to a numpy data type!\") from exc\n",
    "\n",
    "    return np_dtype\n",
    "\n",
    "# Try it out\n",
    "print(_get_awkward_type(events['Muon_pt'].array()))\n",
    "print(_get_awkward_type(events['MET_pt'].array()))\n",
    "print(_get_awkward_type(events['run'].array()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f06b0-d0f1-4b17-9bd1-d33e85bde100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to pack a single awkward array\n",
    "\n",
    "def pack_single_awkward_array(d, arr, dset_name, group_name=None, counter=None):\n",
    "    '''\n",
    "    Packs a 1D awkward array as a dataset/singleton depending on if group_name is given\n",
    "    \n",
    "    Args:\n",
    "        d [dict]: data dictionary created by hepfile.initialize()\n",
    "        arr [ak.Array]: 1D awkward array to pack as either a dataset or a group. If group_name is None\n",
    "                        the arr is packed as a singleton\n",
    "        dset_name [str]: Full path to the dataset.\n",
    "        group_name [str]: name of the group to pack the arr under, default is None\n",
    "        counter [str]: name of the counter in the hepfile for this dataset\n",
    "    '''   \n",
    "    counter_in_hepfile = False\n",
    "    if group_name is not None:\n",
    "\n",
    "        if counter is None:\n",
    "            counter = f\"{group_name}/n{group_name}\"\n",
    "        \n",
    "        # add the counter to the groups dictionary if it is not already in it\n",
    "        if group_name not in d['_GROUPS_']:\n",
    "            d['_GROUPS_'][group_name] = [counter.split('/')[1]]\n",
    "\n",
    "            # We will use this name for the counter later\n",
    "            d['_MAP_DATASETS_TO_DATA_TYPES_'][counter] = int\n",
    "\n",
    "            d['_MAP_DATASETS_TO_COUNTERS_'][group_name] = counter\n",
    "            d['_LIST_OF_COUNTERS_'].append(counter)\n",
    "\n",
    "    else:\n",
    "        counter = '_SINGLETONS_GROUP_/COUNTER'\n",
    "\n",
    "    # Tells us if this is jagged or not\n",
    "    if arr.ndim == 1:\n",
    "        \n",
    "        # Get the datatpe before we flatten it\n",
    "        dtype = _get_awkward_type(arr)\n",
    "        \n",
    "        num = np.ones(len(arr),dtype=int)\n",
    "        \n",
    "        x = ak.to_numpy(arr)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Get the datatpe before we flatten it\n",
    "        dtype = _get_awkward_type(arr)\n",
    "\n",
    "        # This saves the counter as int64, taking up a bit more space\n",
    "        # Probably minimal though. \n",
    "        #num = ak.num(x)\n",
    "        # This saves the counter as int32\n",
    "        num = ak.to_numpy(ak.num(arr)).astype(np.int32)\n",
    "\n",
    "        x = ak.flatten(arr).to_numpy()\n",
    "\n",
    "    d[dset_name] = x\n",
    "\n",
    "    # Not a SINGLETON, the user has passed in a groupname\n",
    "    if group_name is not None:\n",
    "        d['_MAP_DATASETS_TO_DATA_TYPES_'][dset_name] = dtype\n",
    "        d['_MAP_DATASETS_TO_COUNTERS_'][dset_name] = counter\n",
    "        d['_GROUPS_'][group_name].append(dset_name.split('/')[1])\n",
    "        if counter not in d:\n",
    "            d[counter] = num\n",
    "        \n",
    "    # If it is a SINGLETON\n",
    "    else:\n",
    "        d['_MAP_DATASETS_TO_DATA_TYPES_'][dset_name] = dtype\n",
    "        d['_MAP_DATASETS_TO_COUNTERS_'][dset_name] = '_SINGLETONS_GROUP_/COUNTER'\n",
    "        d['_GROUPS_']['_SINGLETONS_GROUP_'].append(dset_name)\n",
    "        if len(d[counter]) == 0:\n",
    "            d[counter] = num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I changed the name of this function to pack multiple awkward arrays.\n",
    "# I agree with you that we should probably also have a function that packs\n",
    "# single awkward arrays that gets called by this function.\n",
    "\n",
    "# d = data dictionary, maybe we have a version of this that automatically\n",
    "# creates the dictionary and returns it?\n",
    "\n",
    "# arr = dictionary of awkward arrays and keys to use as names for the dataset\n",
    "\n",
    "# group_name = group the dataset will belong to\n",
    "\n",
    "# Right now, I am creating a counter \"n{group_name}\", is that what we want?\n",
    "# Or should we allow the user to pass in the counter name, like when\n",
    "# create_group is called?\n",
    "#\n",
    "# Right now, it creates the group each time this function is called\n",
    "# We should have it check to see if the group is already there and if so, \n",
    "# don't add it again.\n",
    "\n",
    "import warnings\n",
    "\n",
    "def pack_multiple_awkward_arrays(d, arr, group_name=None, group_counter_name=None):\n",
    "    '''\n",
    "    Pack an awkward array of arrays into group_name or the singletons group\n",
    "    \n",
    "    Args:\n",
    "        d [dict]: hepfile data dictionary that is returned from hepfile.initialize()\n",
    "        arr [ak.Array]: Awkward array of the group in a set of data\n",
    "        group_name [str]: Name of the group to pack arr into, if None (default) it is \n",
    "                          packed into the signletons group\n",
    "    '''\n",
    "    \n",
    "    # If the user passed in a group, then the datasets will \n",
    "    # be under that group\n",
    "    \n",
    "    # check that arr is an awkward array\n",
    "    if not isinstance(arr, (ak.Array, ak.Record)):\n",
    "        try:\n",
    "            arr = ak.Array(arr)\n",
    "        except Exception as exc:\n",
    "            raise IOError() from exc\n",
    "    \n",
    "    if len(arr.fields) == 0:\n",
    "        raise IOError('The input awkward array must have at least one field value! '+\n",
    "                      'If this is a singleton just provide the name of the singleton as the field')\n",
    "    # Loop over the dictionary that is passed in        \n",
    "    for field in arr.fields:\n",
    "        \n",
    "        # build a name for the hepfile entry\n",
    "        if group_name is None:\n",
    "            # these are singletons\n",
    "            dataset_name = field\n",
    "        else:\n",
    "            # these are regular groups with datasets\n",
    "            dataset_name = f\"{group_name}/{field}\"\n",
    "            \n",
    "        pack_single_awkward_array(d, arr[field], dataset_name, group_name=group_name, counter=group_counter_name)\n",
    "\n",
    "    # We don't need to return the dictionary because in python\n",
    "    # dictionaries are mutable. The dictionary in the function points to \n",
    "    # the same object outside of the function.\n",
    "###############################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e300647-5c51-4d97-ba0e-2a3de78eb078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's how we call it. Though maybe we have an option to have\n",
    "# the data dictionary created inside the function? \n",
    "\n",
    "# Initialize the data dictionary\n",
    "data = hepfile.initialize()\n",
    "\n",
    "# Pack these groups of awkward arrays\n",
    "\n",
    "# This is what it would look like \"by hand\"\n",
    "# A dictionary with the name of the dataset as it is to appear inside the hepfile\n",
    "# and then the actual awkward array (not just the Branch object returned by uproot)\n",
    "#ak_arrays = {'pt': events['Muon_pt'].array(), 'eta': events['Muon_eta'].array(), 'phi':events['Muon_phi'].array(), }\n",
    "\n",
    "# Here I'm packing all the data that are groups/datasets\n",
    "for groups_to_write in ['Muon', 'Electron', 'MET', 'PV']:\n",
    "    ak_arrays = {}\n",
    "    for grouping in groupings[groups_to_write]:\n",
    "        ak_arrays[grouping[1]] = events[grouping[0]].array()\n",
    "    \n",
    "    pack_multiple_awkward_arrays(data, ak_arrays, group_name=groups_to_write)\n",
    "\n",
    "# Now the SINGLETONS\n",
    "ak_arrays = {\"run\":events['run'].array(), \\\n",
    "             \"luminosityBlock\":events['luminosityBlock'].array(), \\\n",
    "             \"event\":events['event'].array()}\n",
    "\n",
    "# Note that there is no group name passed in. \n",
    "pack_multiple_awkward_arrays(data, ak_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b561381-4ae7-46eb-9cd5-91e1d5d37a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['_SINGLETONS_GROUP_/COUNTER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262260d-e47d-4d6a-a96d-2dd7120cb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Electron/nElectron'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cd52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to see what the data dictionary looks like\n",
    "#data\n",
    "\n",
    "print(data['_GROUPS_']['_SINGLETONS_GROUP_'])\n",
    "print()\n",
    "\n",
    "print(data['_MAP_DATASETS_TO_COUNTERS_'])\n",
    "print()\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba272902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write it!\n",
    "\n",
    "# Try it with no compression\n",
    "start = time.time()\n",
    "hepfile.write_to_file('awkward_write_test.h5', data, verbose=False)\n",
    "dt_no_compression = time.time() - start\n",
    "\n",
    "# Try it with compression!\n",
    "start = time.time()\n",
    "hepfile.write_to_file('awkward_write_test_COMP_gzip_OPT_9.h5', data, verbose=False, comp_type=\"gzip\", comp_opts=9)\n",
    "dt_with_compression = time.time() - start\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(f\"Time to write uncompressed: {dt_no_compression}\")\n",
    "print(f\"Time to write   compressed: {dt_with_compression}\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Check out the sizes of the files!\n",
    "\n",
    "!ls -ltr SMHiggsToZZTo4L.root\n",
    "!ls -ltr awkward_write_test.h5\n",
    "!ls -ltr awkward_write_test_COMP_gzip_OPT_9.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,bucket = hepfile.load('awkward_write_test_COMP_gzip_OPT_9.h5', verbose=False)\n",
    "\n",
    "#data,bucket = hepfile.load('awkward_write_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2213c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Electron/nElectron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adfa207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data['Muon/pt']))\n",
    "print(type(data['Muon/pt'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e39a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['Muon/pt'].astype(np.float32)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccef665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ddcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['_MAP_DATASETS_TO_DATA_TYPES_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6645da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['_GROUPS_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb217dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ak.to_numpy(ak.flatten(events['Muon_pt'].array()))\n",
    "\n",
    "type(x)\n",
    "type(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events['Muon_pt'].array()\n",
    "\n",
    "xnum = ak.num(x)\n",
    "\n",
    "print(type(xnum))\n",
    "print(type(xnum[0]))\n",
    "\n",
    "print(xnum)\n",
    "\n",
    "print(xnum[0])\n",
    "\n",
    "print(type(ak.to_numpy(xnum)[0]))\n",
    "print(type(ak.to_numpy(xnum).astype(np.int32)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b3384-02d4-4aaa-967b-833cdcf83e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test loading the hepfile into the awkward array\n",
    "awk, bucket = hepfile.load('awkward_write_test_COMP_gzip_OPT_9.h5', return_type='awkward')\n",
    "awk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf32d45-9c3e-42ea-a076-fc1b2f426189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def awkward_to_hepfile(ak_array, outfile=None, write_hepfile=True, **kwargs):\n",
    "    '''\n",
    "    Write an awkward array with depth <= 2 to a hepfile\n",
    "    \n",
    "    Args:\n",
    "        ak_array [ak.Array]: awkward array with fields of groups/singletons. Under the group fields\n",
    "                             are the dataset fields.\n",
    "        outfile [str]: path to where the hepfile should be written. Default is None and can only be\n",
    "                       None if write_hepfile=False.\n",
    "        write_hepfile [bool]: if True, write the hepfile and return the data dictionary. If False, \n",
    "                              just return the data dictionary without returning. Default is True.\n",
    "        **kwargs: passed to `hepfile.write_to_file`\n",
    "                              \n",
    "    Returns:\n",
    "        Data dictionary in the hepfile\n",
    "    '''\n",
    "    \n",
    "    # _is_valid_awkward(ak_array) # uncomment when in actual software and not in testing\n",
    "    \n",
    "    if write_hepfile is True and outfile is None:\n",
    "        raise IOError('Please provide an outfile path if write_hepfile=True!')\n",
    "        \n",
    "    if write_hepfile is False and outfile is not None:\n",
    "        warnings.warn(\n",
    "            \"You set write_hepfile to False but provided an output file path. \\\n",
    "            This output file path will not be used!\"\n",
    "        )\n",
    "    \n",
    "    data = hepfile.initialize()\n",
    "    for group in ak_array.fields:\n",
    "        \n",
    "        if len(ak_array[group].fields) == 0:\n",
    "            # this is a singleton\n",
    "            pack_multiple_awkward_arrays(data, {group: ak_array[group]})\n",
    "        else:\n",
    "            # these are datasets under group\n",
    "            pack_multiple_awkward_arrays(data, ak_array[group], group_name=group)\n",
    "            \n",
    "    if write_hepfile:\n",
    "        hepfile.write_to_file(outfile, data)\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5ce80-286d-418e-a094-82e0cbe6cc32",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test awkward_to_hepfile\n",
    "\n",
    "d2 = awkward_to_hepfile(awk, write_hepfile=False)\n",
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c90f74",
   "metadata": {},
   "source": [
    "# Scratch code\n",
    "\n",
    "Just a bunch of test code when I was trying to figure this all out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a75c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "groups_to_datasets = {}\n",
    "\n",
    "counters = []\n",
    "\n",
    "for field in events.fields:\n",
    "    \n",
    "    print(field)\n",
    "    \n",
    "    d[field] = []\n",
    "    groups_to_datasets[field] = []\n",
    "    \n",
    "    counters.append(f'n{field}')\n",
    "    \n",
    "    for v in events[field].fields:\n",
    "        groups_to_datasets[field].append(v)\n",
    "        \n",
    "        key = f\"{field}/{v}\"\n",
    "        \n",
    "        x = events[field][v]\n",
    "        \n",
    "        #print(v)\n",
    "        \n",
    "        print(f\"\\t{v}   {x.ndim}\")\n",
    "        \n",
    "        if x.ndim==1:\n",
    "            dtype = x.layout.format\n",
    "            x = ak.to_numpy(x)\n",
    "\n",
    "        else:\n",
    "            dtype = x.layout.content.format\n",
    "            x = ak.flatten(x).to_numpy()\n",
    "\n",
    "\n",
    "        d[key] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c90f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.num(events['Muon']['pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.luminosityBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2afa89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6be6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events['MET']['pt']\n",
    "\n",
    "print(x.ndim)\n",
    "print(events['Muon']['pt'].ndim)\n",
    "print(events['MET']['pt'].ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.layout\n",
    "layout = events['Electron']['pt'].layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.content.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events['MET']['pt']\n",
    "\n",
    "x.layout.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events['MET']['pt']\n",
    "\n",
    "x.layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22837e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events['MET']['pt']\n",
    "\n",
    "try:\n",
    "    x = ak.flatten(x)\n",
    "except:\n",
    "    1\n",
    "x = ak.to_numpy(x)\n",
    "\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08038a5",
   "metadata": {},
   "source": [
    "# Testing out the loop way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ed315",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hepfile.initialize()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "hepfile.create_group(data,group_name='muon',counter='nmuon')\n",
    "hepfile.create_dataset(data,group='muon',dset_name=['px','py','pz'],dtype=float)\n",
    "\n",
    "hepfile.create_dataset(data,dset_name=['luminosity_block'],dtype=int)\n",
    "\n",
    "bucket = hepfile.create_single_bucket(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7698db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81775b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nevents = 100\n",
    "\n",
    "for i in range(nevents):\n",
    "    nmuon = np.random.randint(0,5)\n",
    "    bucket['muon/nmuon'] = nmuon\n",
    "    bucket['muon/px'] = np.random.random(nmuon).tolist()\n",
    "    bucket['muon/py'] = np.random.random(nmuon).tolist()\n",
    "    bucket['muon/pz'] = np.random.random(nmuon).tolist()\n",
    "    \n",
    "    bucket['luminosity_block'] = np.random.randint(100,10000)\n",
    "    \n",
    "    hepfile.pack(data,bucket)\n",
    "\n",
    "hepfile.write_to_file('awkward_write_test_LOOP_FILL.h5', data, verbose=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8640bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,bucket = hepfile.load('awkward_write_test_LOOP_FILL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['luminosity_block']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b50fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
