{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833f7a54-de23-42c3-9539-7f867fbfaf18",
   "metadata": {},
   "source": [
    "# Writing a hepfile from Scratch\n",
    "\n",
    "The method shown in this tutorial is what is done under the hood in the `hepfile.dict_tools.dictlike_to_hepfile` method. This may be preferable for those users who want more control over the structure of their hepfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fb291-9793-4f9c-a12d-84e60fe7e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from hepfile import write as writer\n",
    "from hepfile import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220bb75-f076-4066-a201-d73c81af7389",
   "metadata": {},
   "source": [
    "Once hepfile.write is imported, we need to start by initializing the empty data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fffe4e-de19-4a1d-9b2c-d4da9b49b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data = writer.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515cf60c-9fe5-430d-ab8a-1503ede01b21",
   "metadata": {},
   "source": [
    "Now that the empty data structure is initialized, we must set up groups and datasets. Groups hold datasets and datasets hold data about that group. You can also just create higher level datasets that are considered \"singletons\" which do not correspond to a specific group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1fd13-ce7a-44f8-a6ac-6e49b895e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the groups\n",
    "writer.create_group(data,'jet',counter='njet')\n",
    "writer.create_group(data,'muons',counter='nmuon')\n",
    "\n",
    "# add datasets to different groups\n",
    "writer.create_dataset(data,['e','px','py','pz'],group='jet',dtype=float)\n",
    "writer.create_dataset(data,['algorithm'],group='jet',dtype=int)\n",
    "writer.create_dataset(data,['words'],group='jet',dtype=str)\n",
    "writer.create_dataset(data,['e','px','py','pz'],group='muons',dtype=float)\n",
    "\n",
    "# add a higher level dataset that doesn't have a group, a \"singleton\"\n",
    "writer.create_dataset(data,['METpx','METpy'],dtype=float)\n",
    "\n",
    "# add 75 more singletons to make sure we go over the 256 char limit\n",
    "for i in range(75):\n",
    "    writer.create_dataset(data,f'test{i}',dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90305e-33d3-42c6-bad8-76712703f63b",
   "metadata": {},
   "source": [
    "To start adding data to the groups and datasets we have to generate an empty bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a24843-e480-4df2-a4d6-e027db36bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = writer.create_single_bucket(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457380e2-d7f8-43bd-bb35-c367c8781636",
   "metadata": {},
   "source": [
    "Now that we have the hepfile structure set up, we can generate random data and insert it into the hepfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed60a79-aebc-494b-b78d-c351c2b39a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rando_words = [\"hi\", \"bye\", \"ciao\", \"aloha\"]\n",
    "\n",
    "for i in range(0,10000):\n",
    "\n",
    "    #hepfile.clear_event(event)\n",
    "\n",
    "    njet = 17\n",
    "    bucket['jet/njet'] = njet\n",
    "\n",
    "    for n in range(njet):\n",
    "        bucket['jet/e'].append(np.random.random())\n",
    "        bucket['jet/px'].append(np.random.random())\n",
    "        bucket['jet/py'].append(np.random.random())\n",
    "        bucket['jet/pz'].append(np.random.random())\n",
    "\n",
    "        bucket['jet/algorithm'].append(np.random.randint(-1,1))\n",
    "\n",
    "        bucket['jet/words'].append(np.random.choice(rando_words))\n",
    "\n",
    "    bucket['METpx'] = np.random.random()\n",
    "    bucket['METpy'] = np.random.random()\n",
    "\n",
    "    #hepfile.pack(data,event,EMPTY_OUT_BUCKET=False)\n",
    "    return_value = writer.pack(data,bucket,STRICT_CHECKING=True)\n",
    "    if return_value != 0:\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e08af-966d-4420-af65-6a5a0619cb0d",
   "metadata": {},
   "source": [
    "Finally, we are ready to write this random data to a file called `output.hdf5`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab1dbd-054c-4628-8939-65227f52dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing the file...\")\n",
    "#hdfile = hepfile.write_to_file('output.hdf5',data)\n",
    "hdfile = writer.write_to_file('output_from_scratch.hdf5',data,comp_type='gzip',comp_opts=9,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd304590-9d2f-4b2b-9d7d-563d139410b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output time it took to run write the file\n",
    "write_time = time.time()\n",
    "print(f'Time it took to write: {write_time-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55add264-c7d2-4c47-a5d5-8a279d0a21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, bucket = load('output_from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d6c41e-fe01-4c38-ae7e-0ff49bfffe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_time = time.time()\n",
    "print(f'Time it took to read: {read_time-write_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49174717-fbab-4033-8bd3-b29e7e66c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881711bb-ce40-4f5e-aa19-640f5f65faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['_SINGLETONS_GROUP_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e24128e-5baf-479f-90ef-d82d2610f4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
