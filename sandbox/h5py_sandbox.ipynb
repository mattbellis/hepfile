{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e0006-b455-4178-aabc-496fb600ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "import string\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9476925c-ec0a-4e82-95f2-19b22b97c941",
   "metadata": {},
   "source": [
    "# Writing strings to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa50762-425f-43b3-a63b-04da3504df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=['this','is','a','sentence']\n",
    "data = []\n",
    "\n",
    "for i in range(10000):\n",
    "    data += sentence\n",
    "print(len(data))\n",
    "longest_word=len(max(data, key=len))\n",
    "print('longest_word=',longest_word)\n",
    "\n",
    "dt = h5py.special_dtype(vlen=str)\n",
    "\n",
    "arr = np.array(data,dtype='S'+str(longest_word))\n",
    "\n",
    "with h5py.File('outfile.h5','w') as h5File:\n",
    "    dset = h5File.create_dataset('words',data=arr,dtype=dt, compression='gzip',compression_opts=9)\n",
    "    print(dset.shape, dset.dtype)\n",
    "\n",
    "    h5File.flush()\n",
    "    h5File.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ba5f1-6bc0-4dae-81e0-387d600b17c4",
   "metadata": {},
   "source": [
    "# Another shot at writing and reading strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b3dca-f72f-4c83-8018-baa4729db411",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5File=h5py.File('xxx.h5','w')\n",
    "\n",
    "strList=['asas','asas','asas']\n",
    "\n",
    "#dt = h5py.special_dtype(vlen=str)\n",
    "dt = h5py.string_dtype(encoding='utf-8')\n",
    "\n",
    "dset = h5File.create_dataset('strings',(len(strList),1),dtype=dt)\n",
    "for i,s in enumerate(strList):\n",
    "    dset[i] = s\n",
    "\n",
    "h5File.flush()\n",
    "h5File.close()\n",
    "\n",
    "\n",
    "\n",
    "#################\n",
    "\n",
    "f = h5py.File('xxx.h5', 'r')\n",
    "\n",
    "print(list(f.keys()))\n",
    "\n",
    "print(f['strings'])\n",
    "x = f['strings']\n",
    "\n",
    "for a in x:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bbdfdc-e480-4dd4-b6f8-2200949806b9",
   "metadata": {},
   "source": [
    "# Writing groups under groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d4f69-91fb-4d5c-a951-4e1da4847c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilename = 'foo.h5'\n",
    "\n",
    "if os.path.exists(outfilename):\n",
    "  os.remove(outfilename)\n",
    "else:\n",
    "  print(f\"{outfilename} file does not exist\")\n",
    "\n",
    "\n",
    "f = h5py.File(outfilename,'w')\n",
    "print(f.name)\n",
    "\n",
    "grp = f.create_group(\"bar\")\n",
    "subgrp = grp.create_group(\"baz\")\n",
    "\n",
    "print(subgrp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80598462-713b-4447-84cd-a9c31e0762b2",
   "metadata": {},
   "source": [
    "# Timing tests for large writes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c6392-7648-404f-99b8-be990e45a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilename = 'data_TEST.h5'\n",
    "\n",
    "if os.path.exists(outfilename):\n",
    "  os.remove(outfilename)\n",
    "else:\n",
    "  print(f\"{outfilename} file does not exist\")\n",
    "\n",
    "f = h5py.File(outfilename,'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f7ca8-5944-4709-b568-800d2906d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3246d0-f557-4e51-919b-8eddf8fd95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(''.join(np.random.choice(list(string.ascii_lowercase), size=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da1b04-0187-4d05-83f8-c4a5564558d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngroups = 10\n",
    "nchars_in_name = 5\n",
    "\n",
    "ndatasets_in_group = 20\n",
    "\n",
    "data = {}\n",
    "\n",
    "# Make the groups\n",
    "for n in range(ngroups):\n",
    "    name = ''.join(np.random.choice(list(string.ascii_lowercase), size=nchars_in_name))\n",
    "    \n",
    "    # Keep track of our data\n",
    "    data[name] = {}\n",
    "    \n",
    "    group_names = list(f.keys())\n",
    "    \n",
    "    if name not in group_names:\n",
    "        grp = f.create_group(name)\n",
    "        \n",
    "        # Make the datasets in each group\n",
    "        for nd in range(ndatasets_in_group):\n",
    "            dname = ''.join(np.random.choice(list(string.ascii_lowercase), size=nchars_in_name))\n",
    "\n",
    "            data[name][dname] = []\n",
    "            # Create this at write time\n",
    "            #dset = grp.create_dataset(dname, dtype='f')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886533d6-fcab-4a14-95c2-50fd80b854ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc68040-a9b4-45ab-ab31-d62edb18a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printname(name):\n",
    "    print(name)\n",
    "#f.visit(printname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213c6bd-cd99-4f72-8372-b2ecde7df4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill the data\n",
    "nevents = 400000\n",
    "nentries_per_group = (1, 10)\n",
    "\n",
    "for group in data.keys():\n",
    "    nentries = nevents*np.random.randint(nentries_per_group[0],nentries_per_group[1])\n",
    "    print(f\"{group}: {nentries}\")\n",
    "    for dset in data[group].keys():\n",
    "        data[group][dset] = np.random.random(nentries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c917e-a1b1-4e50-9150-5a70f23695be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da585b-6076-4085-91d8-aedb1f88fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the data\n",
    "\n",
    "start = time.time()\n",
    "print(f\"Starting to fill file with {nevents} events at {start}\")\n",
    "\n",
    "for group in data.keys():\n",
    "    grp = f[group]\n",
    "    print(f\"Writing {group} and {len(data[group].keys())} datasets\")\n",
    "    for dname in data[group].keys():\n",
    "        #print(list(f[group].keys()))\n",
    "        if dname in f[group].keys():\n",
    "            fullname = f\"{group}/{dname}\"\n",
    "            del f[fullname]\n",
    "        else:\n",
    "            fullname = f\"{group}/{dname}\"\n",
    "            #print(f\"\\t{fullname}\")\n",
    "            dset = grp.create_dataset(dname, data=data[group][dname],compression=\"gzip\", compression_opts=9)\n",
    "\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Finished filling file with {nevents} events at {stop}\")\n",
    "print(f\"Time to fill: {stop-start:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de7336-70f6-4ff5-9c43-94a9bf8525c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80661447-89b4-4050-9871-61f3ec49577b",
   "metadata": {},
   "source": [
    "# Try opening the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67d23e-0a78-4109-a8a5-02253e3258ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(outfilename,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1db40-8dff-4079-a805-64da454d8c2f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def printname(name):\n",
    "    print(name)\n",
    "f.visit(printname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da9016-9fe0-4d20-9366-0373d358e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k0 = list(f.keys())[0]\n",
    "k1 = list(f[k0].keys())[0]\n",
    "\n",
    "x = f[f'{k0}/{k1}'][()] # This last bit returns a numpy array\n",
    "\n",
    "print(type(x))\n",
    "print(x)\n",
    "\n",
    "#x.values\n",
    "\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250b8a0-10b5-4c1d-b8f1-8b6cfcddd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x,bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba44f9-fe7c-45b8-aba9-51431de6ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.random.random(len(x)),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128ca47-4d40-49bb-bf0a-3e9c90c2c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = f[k0]\n",
    "print(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf90504c-18fc-4831-b6ed-6cb1f57b15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = grp[k1][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94911f4-e5e6-427b-b747-006f06d43684",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)\n",
    "plt.hist(x,bins=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ea126-45fb-45ce-9829-e514cb6a63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in f.keys():\n",
    "    grp = f[group]\n",
    "    print(group)\n",
    "    for i,dname in enumerate(f[group].keys()):\n",
    "        fullname = f\"{group}/{dname}\"\n",
    "        #print(f[fullname])\n",
    "        #if i == 0:\n",
    "        #    plt.figure()\n",
    "        #    plt.hist(f[fullname],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6c302-6a71-4780-9f75-0e5b39a13e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b75988",
   "metadata": {},
   "source": [
    "# Writing a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ae4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just writing strings\n",
    "\n",
    "h5File=h5py.File('xxx.h5','w')\n",
    "\n",
    "strList=['asas','asas','asas']\n",
    "\n",
    "#dt = h5py.special_dtype(vlen=str)\n",
    "dt = h5py.string_dtype(encoding='utf-8')\n",
    "\n",
    "dset = h5File.create_dataset('strings',(len(strList),1),dtype=dt)\n",
    "for i,s in enumerate(strList):\n",
    "    dset[i] = s\n",
    "\n",
    "h5File.flush()\n",
    "h5File.close()\n",
    "\n",
    "\n",
    "\n",
    "#################\n",
    "\n",
    "f = h5py.File('xxx.h5', 'r')\n",
    "\n",
    "print(list(f.keys()))\n",
    "\n",
    "print(f['strings'])\n",
    "x = f['strings']\n",
    "\n",
    "for a in x:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860fb881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a header\n",
    "\n",
    "filename = 'header_test.h5'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "else:\n",
    "    print(\"The file does not exist\")\n",
    "\n",
    "\n",
    "h5File=h5py.File(filename,'w')\n",
    "\n",
    "header_group_name = 'header'\n",
    "\n",
    "header_strings = []\n",
    "header_strings.append('#*********************************************************************)')\n",
    "header_strings.append('# Tag name for the run (one word)                                    *')\n",
    "header_strings.append('#*********************************************************************')\n",
    "header_strings.append('  tag_1 = run_tag ! name of the run')\n",
    "header_strings.append('#*********************************************************************')\n",
    "header_strings.append('# Number of events and rnd seed                                      *')\n",
    "header_strings.append('# Warning: Do not generate more than 1M events in a single run       *')\n",
    "header_strings.append('# If you want to run Pythia, avoid more than 50k events in a run.    *')\n",
    "header_strings.append('#*********************************************************************')\n",
    "header_strings.append('  1000  = nevents ! Number of unweighted events requested)')\n",
    "header_strings.append(' 66 = iseed ! rnd seed (0=assigned automatically=default))')\n",
    "header_strings.append('#*********************************************************************')\n",
    "header_strings.append('# Collider type and energy                                           *')\n",
    "header_strings.append('# lpp: 0=No PDF, 1=proton, -1=antiproton, 2=photon from proton,      *')\n",
    "header_strings.append('#                                         3=photon from electron     *')\n",
    "header_strings.append('#*********************************************************************')\n",
    "header_strings.append('  1 = lpp1 ! beam 1 type')\n",
    "header_strings.append('  1 = lpp2 ! beam 2 type')\n",
    "header_strings.append('  6500.0    = ebeam1 ! beam 1 total energy in GeV')\n",
    "header_strings.append('  6500.0    = ebeam2 ! beam 2 total energy in GeV')\n",
    "header_strings.append('')\n",
    "\n",
    "\n",
    "#strList=['asas','asas','asas']\n",
    "\n",
    "dt = h5py.string_dtype(encoding='utf-8')\n",
    "\n",
    "grp = h5File.create_group(header_group_name)\n",
    "dset = grp.create_dataset('lines',(len(header_strings),1),dtype=dt)\n",
    "\n",
    "print(len(header_strings))\n",
    "print(dset)\n",
    "\n",
    "for i,s in enumerate(header_strings):\n",
    "    print(s)\n",
    "    dset[i] = s\n",
    "\n",
    "h5File.flush()\n",
    "h5File.close()\n",
    "\n",
    "\n",
    "\n",
    "#################\n",
    "\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "print(list(f.keys()))\n",
    "\n",
    "print(f[header_group_name])\n",
    "grp = f[header_group_name]\n",
    "\n",
    "for line in grp['lines']:\n",
    "    print(line[0].decode()) # Need the .decode because these are stored as binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pythonhow.com/how/check-if-a-string-is-a-float/#:~:text=To%20check%20if%20a%20string%20is%20a%20number%20(float)%20in,casted%20to%20float%20or%20not.\n",
    "\n",
    "def is_float(string):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_int(string):\n",
    "    try:\n",
    "        int(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_data_type_of_string(string):\n",
    "    # First, check float\n",
    "    if is_int(string):\n",
    "        return 'int'\n",
    "    \n",
    "    # Check float has to come after check int\n",
    "    elif is_float(string):\n",
    "        return 'float'\n",
    "    \n",
    "    else:\n",
    "        return 'str'\n",
    "\n",
    "    \n",
    "print(check_data_type_of_string('10.0'))\n",
    "print(check_data_type_of_string('10'))\n",
    "print(check_data_type_of_string('ten eight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a header\n",
    "\n",
    "filename = 'header_test_values.h5'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "else:\n",
    "    print(\"The file does not exist\")\n",
    "\n",
    "\n",
    "h5File=h5py.File(filename,'w')\n",
    "\n",
    "header_group_name = 'header_values'\n",
    "\n",
    "\n",
    "# header_strings = []\n",
    "# header_strings.append('#*********************************************************************)')\n",
    "# header_strings.append('# Tag name for the run (one word)                                    *')\n",
    "# header_strings.append('#*********************************************************************')\n",
    "# header_strings.append('  tag_1 = run_tag ! name of the run')\n",
    "# header_strings.append('#*********************************************************************')\n",
    "# header_strings.append('# Number of events and rnd seed                                      *')\n",
    "# header_strings.append('# Warning: Do not generate more than 1M events in a single run       *')\n",
    "# header_strings.append('# If you want to run Pythia, avoid more than 50k events in a run.    *')\n",
    "# header_strings.append('#*********************************************************************')\n",
    "# header_strings.append('  1000  = nevents ! Number of unweighted events requested)')\n",
    "# header_strings.append(' 66 = iseed ! rnd seed (0=assigned automatically=default))')\n",
    "# header_strings.append('#*********************************************************************')\n",
    "# header_strings.append('# Collider type and energy                                           *')\n",
    "# header_strings.append('# lpp: 0=No PDF, 1=proton, -1=antiproton, 2=photon from proton,      *')\n",
    "# header_strings.append('#                                         3=photon from electron     *')\n",
    "# header_strings.append('#*********************************************************************')\n",
    "# header_strings.append('  1 = lpp1 ! beam 1 type')\n",
    "# header_strings.append('  1 = lpp2 ! beam 2 type')\n",
    "# header_strings.append('  6500.0    = ebeam1 ! beam 1 total energy in GeV')\n",
    "# header_strings.append('  6500.0    = ebeam2 ! beam 2 total energy in GeV')\n",
    "# header_strings.append('')\n",
    "\n",
    "\n",
    "header_strings = '''\n",
    "#*********************************************************************\n",
    "# Tag name for the run (one word)                                    *\n",
    "#*********************************************************************\n",
    "  tag_1 = run_tag ! name of the run\n",
    "# Number of events and rnd seed                                      *\n",
    "# Warning: Do not generate more than 1M events in a single run       *\n",
    "# If you want to run Pythia, avoid more than 50k events in a run.    *\n",
    "#*********************************************************************\n",
    "  1000  = nevents ! Number of unweighted events requested\n",
    "  66 = iseed ! rnd seed (0=assigned automatically=default)\n",
    "#*********************************************************************\n",
    "# Collider type and energy                                           *\n",
    "# lpp: 0=No PDF, 1=proton, -1=antiproton, 2=photon from proton,      *\n",
    "#                                         3=photon from electron     *\n",
    "#*********************************************************************\n",
    "  1 = lpp1 ! beam 1 type\n",
    "  1 = lpp2 ! beam 2 type\n",
    "  6500.0    = ebeam1 ! beam 1 total energy in GeV\n",
    "  6500.0    = ebeam2 ! beam 2 total energy in GeV\n",
    "'''\n",
    "\n",
    "if isinstance(header_strings, str):\n",
    "    # turn it into a list\n",
    "    strings = header_strings.split('\\n')\n",
    "    if strings[0] == '':\n",
    "        del strings[0]\n",
    "    if strings[-1] == '':\n",
    "        del strings[-1]\n",
    "    \n",
    "    header_strings = strings\n",
    "    \n",
    "\n",
    "# Parse the file\n",
    "\n",
    "values = []\n",
    "parameters = []\n",
    "comments = []\n",
    "datatypes = []\n",
    "\n",
    "for h in header_strings:\n",
    "    #print(h)\n",
    "    if len(h)>0 and h[0] != '#':\n",
    "        a = h.split('=')[0].strip()\n",
    "        b = h.split('=')[1].split('!')[0].strip()\n",
    "        c = h.split('!')[1].strip()\n",
    "        \n",
    "        print(a,b,c)\n",
    "\n",
    "        values.append(a)\n",
    "        parameters.append(b)\n",
    "        comments.append(c)\n",
    "        datatypes.append(check_data_type_of_string(a))\n",
    "\n",
    "print(values)\n",
    "print(parameters)\n",
    "print(comments)\n",
    "print(datatypes)\n",
    "####################################################################\n",
    "        \n",
    "        \n",
    "# Write to h5py\n",
    "dt = h5py.string_dtype(encoding='utf-8')\n",
    "\n",
    "grp = h5File.create_group(header_group_name)\n",
    "dset1 = grp.create_dataset('values',(len(values),1),dtype=dt)\n",
    "dset2 = grp.create_dataset('parameters',(len(parameters),1),dtype=dt)\n",
    "dset3 = grp.create_dataset('comments',(len(comments),1),dtype=dt)\n",
    "dset4 = grp.create_dataset('datatypes',(len(datatypes),1),dtype=dt)\n",
    "\n",
    "print(len(values))\n",
    "print(dset)\n",
    "\n",
    "for i in range(len(values)):\n",
    "    dset1[i] = values[i]\n",
    "    dset2[i] = parameters[i]\n",
    "    dset3[i] = comments[i]\n",
    "    dset4[i] = datatypes[i]\n",
    "\n",
    "h5File.flush()\n",
    "h5File.close()\n",
    "\n",
    "\n",
    "\n",
    "#################\n",
    "\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "print(list(f.keys()))\n",
    "\n",
    "print(f[header_group_name])\n",
    "group = f[header_group_name]\n",
    "\n",
    "\n",
    "# Why is each entry a list of one val? Is it because we do the (len(values),1) above?\n",
    "\n",
    "for a in group:\n",
    "    print(\"-----------\")\n",
    "    print(a)\n",
    "    for values in group[a]:\n",
    "        print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fefa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = f['header_values/comments']\n",
    "\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c807d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary\n",
    "\n",
    "#################\n",
    "\n",
    "d = {}\n",
    "\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "print(list(f.keys()))\n",
    "\n",
    "print(f[header_group_name])\n",
    "group = f[header_group_name]\n",
    "\n",
    "comments = group['comments']\n",
    "parameters = group['parameters']\n",
    "values = group['values']\n",
    "datatypes = group['datatypes']\n",
    "\n",
    "print(parameters[0])\n",
    "\n",
    "nvals = len(comments)\n",
    "print(nvals)\n",
    "\n",
    "for i in range(nvals):\n",
    "    value = values[i][0].decode()\n",
    "    datatype = datatypes[i][0].decode()\n",
    "    if datatype=='float':\n",
    "        value = float(value)\n",
    "    elif datatype=='int':\n",
    "        value = int(value)\n",
    "    d[parameters[i][0].decode()] = {'value':value , 'comments': comments[i][0].decode()}\n",
    "\n",
    "      \n",
    "#print(d)\n",
    "for key in d.keys():\n",
    "    print(key, d[key])\n",
    "print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebd23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(parameters).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe\n",
    "\n",
    "#################\n",
    "\n",
    "d = {'parameters':[], 'values':[], 'comments':[], 'dtypes':[]}\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "print(list(f.keys()))\n",
    "print(f[header_group_name])\n",
    "\n",
    "group = f[header_group_name]\n",
    "comments = group['comments']\n",
    "parameters = group['parameters']\n",
    "values = group['values']\n",
    "datatypes = group['datatypes']\n",
    "\n",
    "print(parameters[0])\n",
    "\n",
    "nvals = len(comments)\n",
    "print(nvals)\n",
    "\n",
    "for i in range(nvals):\n",
    "    d['parameters'].append(parameters[i][0].decode())\n",
    "    d['values'].append(values[i][0].decode())\n",
    "    d['dtypes'].append(datatypes[i][0].decode())\n",
    "    d['comments'].append(comments[i][0].decode())\n",
    "\n",
    "for key in d.keys():\n",
    "    print(key, d[key])\n",
    "print()\n",
    "\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a header\n",
    "\n",
    "filename = 'header_test_values.h5'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "else:\n",
    "    print(\"The file does not exist\")\n",
    "\n",
    "\n",
    "h5File=h5py.File(filename,'w')\n",
    "\n",
    "header_group_name = 'header_values'\n",
    "\n",
    "\n",
    "# header_strings = []\n",
    "# header_strings.append('#*********************************************************************)')\n",
    "# header_strings.append('# Tag name for the run (one word)                                    *')\n",
    "# header_strings.append('#*********************************************************************')\n",
    "# header_strings.append('  tag_1 = run_tag ! name of the run')\n",
    "# header_strings.append('#*********************************************************************')\n",
    "# header_strings.append('# Number of events and rnd seed                                      *')\n",
    "# header_strings.append('# Warning: Do not generate more than 1M events in a single run       *')\n",
    "# header_strings.append('# If you want to run Pythia, avoid more than 50k events in a run.    *')\n",
    "# header_strings.append('#*********************************************************************')\n",
    "# header_strings.append('  1000  = nevents ! Number of unweighted events requested)')\n",
    "# header_strings.append(' 66 = iseed ! rnd seed (0=assigned automatically=default))')\n",
    "# header_strings.append('#*********************************************************************')\n",
    "# header_strings.append('# Collider type and energy                                           *')\n",
    "# header_strings.append('# lpp: 0=No PDF, 1=proton, -1=antiproton, 2=photon from proton,      *')\n",
    "# header_strings.append('#                                         3=photon from electron     *')\n",
    "# header_strings.append('#*********************************************************************')\n",
    "# header_strings.append('  1 = lpp1 ! beam 1 type')\n",
    "# header_strings.append('  1 = lpp2 ! beam 2 type')\n",
    "# header_strings.append('  6500.0    = ebeam1 ! beam 1 total energy in GeV')\n",
    "# header_strings.append('  6500.0    = ebeam2 ! beam 2 total energy in GeV')\n",
    "# header_strings.append('')\n",
    "\n",
    "\n",
    "header_strings = '''\n",
    "#*********************************************************************\n",
    "# Tag name for the run (one word)                                    *\n",
    "#*********************************************************************\n",
    "  tag_1 = run_tag ! name of the run\n",
    "# Number of events and rnd seed                                      *\n",
    "# Warning: Do not generate more than 1M events in a single run       *\n",
    "# If you want to run Pythia, avoid more than 50k events in a run.    *\n",
    "#*********************************************************************\n",
    "  1000  = nevents ! Number of unweighted events requested\n",
    "  66 = iseed ! rnd seed (0=assigned automatically=default)\n",
    "#*********************************************************************\n",
    "# Collider type and energy                                           *\n",
    "# lpp: 0=No PDF, 1=proton, -1=antiproton, 2=photon from proton,      *\n",
    "#                                         3=photon from electron     *\n",
    "#*********************************************************************\n",
    "  1 = lpp1 ! beam 1 type\n",
    "  1 = lpp2 ! beam 2 type\n",
    "  6500.0    = ebeam1 ! beam 1 total energy in GeV\n",
    "  6500.0    = ebeam2 ! beam 2 total energy in GeV\n",
    "'''\n",
    "\n",
    "if isinstance(header_strings, str):\n",
    "    # turn it into a list\n",
    "    strings = header_strings.split('\\n')\n",
    "    if strings[0] == '':\n",
    "        del strings[0]\n",
    "    if strings[-1] == '':\n",
    "        del strings[-1]\n",
    "    \n",
    "    header_strings = strings\n",
    "    \n",
    "\n",
    "# Parse the file\n",
    "\n",
    "values = []\n",
    "parameters = []\n",
    "comments = []\n",
    "datatypes = []\n",
    "\n",
    "for h in header_strings:\n",
    "    #print(h)\n",
    "    if len(h)>0 and h[0] != '#':\n",
    "        a = h.split('=')[0].strip()\n",
    "        b = h.split('=')[1].split('!')[0].strip()\n",
    "        c = h.split('!')[1].strip()\n",
    "        \n",
    "        print(a,b,c)\n",
    "\n",
    "        values.append(a)\n",
    "        parameters.append(b)\n",
    "        comments.append(c)\n",
    "        datatypes.append(check_data_type_of_string(a))\n",
    "\n",
    "print(values)\n",
    "print(parameters)\n",
    "print(comments)\n",
    "print(datatypes)\n",
    "####################################################################\n",
    "        \n",
    "        \n",
    "# Write to h5py\n",
    "dt = h5py.string_dtype(encoding='utf-8')\n",
    "\n",
    "grp = h5File.create_group(header_group_name)\n",
    "dset1 = grp.create_dataset('values',(len(values),1),dtype=dt, data=values)\n",
    "dset2 = grp.create_dataset('parameters',(len(parameters),1),dtype=dt, data=parameters)\n",
    "dset3 = grp.create_dataset('comments',(len(comments),1),dtype=dt, data=comments)\n",
    "dset4 = grp.create_dataset('datatypes',(len(datatypes),1),dtype=dt, data=datatypes)\n",
    "\n",
    "print(len(values))\n",
    "print(dset)\n",
    "\n",
    "#for i in range(len(values)):\n",
    "#    dset1[i] = values[i]\n",
    "#    dset2[i] = parameters[i]\n",
    "#    dset3[i] = comments[i]\n",
    "#    dset4[i] = datatypes[i]\n",
    "\n",
    "h5File.flush()\n",
    "h5File.close()\n",
    "\n",
    "\n",
    "\n",
    "#################\n",
    "\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "print(list(f.keys()))\n",
    "\n",
    "print(f[header_group_name])\n",
    "group = f[header_group_name]\n",
    "\n",
    "\n",
    "# Why is each entry a list of one val? Is it because we do the (len(values),1) above?\n",
    "\n",
    "for a in group:\n",
    "    print(\"-----------\")\n",
    "    print(a)\n",
    "    for values in group[a]:\n",
    "        print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4c7caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 'ten']\n",
    "x = np.array(x).astype(str)\n",
    "print(x)\n",
    "\n",
    "\n",
    "x = (1, 2, 3, 'ten')\n",
    "x = np.array(x).astype(str)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63216c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.__iter__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b75d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_object = 'x'\n",
    "\n",
    "try:\n",
    "    some_object_iterator = iter(some_object)\n",
    "except TypeError as te:\n",
    "    some_object = [some_object]\n",
    "    \n",
    "print(some_object)\n",
    "print(type(some_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f435842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
