{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696cf0a9-02fc-42bb-912d-9c72d5f02538",
   "metadata": {},
   "source": [
    "# Working with hepfile Metadata and Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73702fc0-7334-4404-92c2-fd06b98f4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hepfile as hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d08dd7-c441-47b5-9d56-ccfd38059e8c",
   "metadata": {},
   "source": [
    "Let's start by writing a simple hepfile, just like the one from the `Writing hepfiles from Dictionaries` tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72de8f18-fcec-452b-9fc9-16b6a4df1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data\n",
    "\n",
    "event1 = {\n",
    "    'jet': {\n",
    "        'px': [1,2,3],\n",
    "        'py': [1,2,3]\n",
    "     },\n",
    "    'muons': {\n",
    "        'px': [1,2,3],\n",
    "        'py': [1,2,3]\n",
    "     },\n",
    "    'nParticles': 3\n",
    "    }\n",
    "\n",
    "event2 = {\n",
    "    'jet': {\n",
    "        'px': [3,4,6,7],\n",
    "        'py': [3,4,6,7]\n",
    "     },\n",
    "    'muons': {\n",
    "        'px': [3,4,6,7],\n",
    "        'py': [3,4,6,7],\n",
    "        },\n",
    "    'nParticles': 4\n",
    "    }\n",
    "\n",
    "events = [event1, event2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c63d4a-f1c9-43b5-991f-7af2503e10f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing the hdf5 file from the awkward array...\n",
      "Metadata added\n",
      "[{jet: {px: [1, ..., 3], py: [...]}, muons: {px: ..., ...}, ...},\n",
      " {jet: {px: [3, ..., 7], py: [...]}, muons: {px: ..., ...}, ...}]\n"
     ]
    }
   ],
   "source": [
    "# write the data to a hepfile\n",
    "filename = 'output_from_dict.hdf5'\n",
    "data = hf.dict_tools.dictlike_to_hepfile(events, filename)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811254cc-c7b2-43de-966a-2e08ac09454f",
   "metadata": {},
   "source": [
    "## Hepfile Metadata\n",
    "Metadata is stored using the hdf5 attributes ability and can be accessed at the file level, group level, and dataset level. The following subsections will give examples on writing and accessing each of these types of metadata.\n",
    "\n",
    "### Writing File Level Metadata\n",
    "To write file level metadata, we use the `hepfile.write_file_metadata` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8dc6c64-97a3-4353-8e03-11ce712eea4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function write_file_metadata in module hepfile.write:\n",
      "\n",
      "write_file_metadata(filename: 'str', mydict: 'dict' = {}, write_default_values: 'bool' = True, append: 'bool' = True) -> 'h5.File'\n",
      "    Writes file metadata in the attributes of an HDF5 file\n",
      "    \n",
      "    Args:\n",
      "    filename (string): Name of output file\n",
      "    \n",
      "    mydict (dictionary): Metadata desired by user\n",
      "    \n",
      "    write_default_values (boolean): True if user wants to write/update the \n",
      "                                        default metadata: date, hepfile version, \n",
      "                                        h5py version, numpy version, and Python \n",
      "                                        version, false if otherwise.\n",
      "    \n",
      "    append (boolean): True if user wants to keep older metadata, false otherwise.\n",
      "    \n",
      "    Returns:\n",
      "    hdoutfile (HDF5): File with new metadata\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hf.write_file_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa1786-88ca-4e74-b0d4-e4893aaeecb9",
   "metadata": {},
   "source": [
    "As you can see above, the `write_file_metadata` function has an optional `mydict` argument for you to write additional file metadata to. By default, the date, hepfile version, h5py version, numpy version, and python version are written to the file metadata as well. This can be changed by setting the `write_default_values = False`. The `write_file_metadata` function also requires the filename to which the metadata is saved.  Finally, the `append` argument allows the user to decide whether to append or overwrite existing metadata. Turning `append=False` can be very dangerous because important information for reading and writing hepfiles is stored in the metadata, only do this if you know what you're doing!\n",
    "\n",
    "To update the file metadata, let's just add an author name and institution to the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b5122c0-15b6-4254-aead-cc1d79ed2ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata added\n"
     ]
    }
   ],
   "source": [
    "meta = {'Author': 'Your Name',\n",
    "        'Institution': 'Siena College'}\n",
    "\n",
    "hf.write_file_metadata(filename, meta);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187c1655-0f61-4f0d-bd02-f434a91eb8cd",
   "metadata": {},
   "source": [
    "### Reading File Level Metadata\n",
    "\n",
    "To view the file level metadata, we can use the `hf.print_file_metadata` function which simply takes a file name and prints out the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e407535-1d17-4b1a-be43-ef559fc9678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                 : 2023-06-21 13:40:21.367753\n",
      "_NUMBER_OF_BUCKETS_  : 2\n",
      "awkward_version      : 2.2.2\n",
      "h5py_version         : 3.7.0\n",
      "hepfile_version      : 0.1.3\n",
      "numpy_version        : 1.21.5\n",
      "python_version       : 3.9.16 (main, Mar  1 2023, 18:22:10) \n",
      "[GCC 11.2.0]\n",
      "Author               : Your Name\n",
      "Institution          : Siena College\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hf.print_file_metadata(filename);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb7aaa6-e0f9-45c0-91ad-f0bac9bec29e",
   "metadata": {},
   "source": [
    "As you can see, the default information is in this metadata and so is the Author's name and Institution that we added earlier! To instead get the metadata as a dictionary, we can use the `hf.get_file_metadata` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b031f7-bc1e-46c4-be23-e4bba5e83703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Name\n",
      "Siena College\n"
     ]
    }
   ],
   "source": [
    "out_meta = hf.get_file_metadata(filename)\n",
    "print(out_meta['Author'])\n",
    "print(out_meta['Institution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b081e9b8-c92b-4809-9176-22d997abab9b",
   "metadata": {},
   "source": [
    "### Writing Group and Dataset Metadata\n",
    "\n",
    "Just like classic hdf5 files, hepfiles can also have metadata attached directly to the groups and/or datasets. This allows us to include important information about a specific group or things like units to the datasets. This needs to be done directly on a hepfile data object. So, let's try to edit the data object from above and add some group metadata.\n",
    "\n",
    "First, we need to convert the data object from an awkward array into a more classical form using `hf.awkward_tools.awkward_to_hepfile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78974f5f-7e0d-4896-bcf0-0d8ce4728d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_GROUPS_': {'_SINGLETONS_GROUP_': ['COUNTER', 'nParticles'],\n",
       "  'jet': ['njet', 'px', 'py'],\n",
       "  'muons': ['nmuons', 'px', 'py']},\n",
       " '_MAP_DATASETS_TO_COUNTERS_': {'_SINGLETONS_GROUP_': '_SINGLETONS_GROUP_/COUNTER',\n",
       "  'jet': 'jet/njet',\n",
       "  'jet/px': 'jet/njet',\n",
       "  'jet/py': 'jet/njet',\n",
       "  'muons': 'muons/nmuons',\n",
       "  'muons/px': 'muons/nmuons',\n",
       "  'muons/py': 'muons/nmuons',\n",
       "  'nParticles': '_SINGLETONS_GROUP_/COUNTER'},\n",
       " '_LIST_OF_COUNTERS_': ['_SINGLETONS_GROUP_/COUNTER',\n",
       "  'jet/njet',\n",
       "  'muons/nmuons'],\n",
       " '_SINGLETONS_GROUP_/COUNTER': [1, 1],\n",
       " '_MAP_DATASETS_TO_DATA_TYPES_': {'_SINGLETONS_GROUP_/COUNTER': int,\n",
       "  'jet/njet': int,\n",
       "  'jet/px': numpy.int64,\n",
       "  'jet/py': numpy.int64,\n",
       "  'muons/nmuons': int,\n",
       "  'muons/px': numpy.int64,\n",
       "  'muons/py': numpy.int64,\n",
       "  'nParticles': numpy.int64},\n",
       " '_META_': {},\n",
       " 'jet/njet': <Array [3, 4] type='2 * int64'>,\n",
       " 'jet/px': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'jet/py': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'muons/nmuons': <Array [3, 4] type='2 * int64'>,\n",
       " 'muons/px': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'muons/py': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'nParticles': <Array [3, 4] type='2 * int64'>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = hf.awkward_tools.awkward_to_hepfile(data, write_hepfile=False)\n",
    "newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10806053-cab9-458b-8f71-e16b38deab73",
   "metadata": {},
   "source": [
    "Now that we have a more classical data object, we can use the `hf.add_meta` to add metadata to the protected `_META_` group. `hf.add_meta` takes in a data object, a group (or singleton or dataset) name, and the metadata to add. Let's first add metadata to the `muons` group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0eb20a1-c9a4-4e23-a7b2-f1966f5f4875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_GROUPS_': {'_SINGLETONS_GROUP_': ['COUNTER', 'nParticles'],\n",
       "  'jet': ['njet', 'px', 'py'],\n",
       "  'muons': ['nmuons', 'px', 'py']},\n",
       " '_MAP_DATASETS_TO_COUNTERS_': {'_SINGLETONS_GROUP_': '_SINGLETONS_GROUP_/COUNTER',\n",
       "  'jet': 'jet/njet',\n",
       "  'jet/px': 'jet/njet',\n",
       "  'jet/py': 'jet/njet',\n",
       "  'muons': 'muons/nmuons',\n",
       "  'muons/px': 'muons/nmuons',\n",
       "  'muons/py': 'muons/nmuons',\n",
       "  'nParticles': '_SINGLETONS_GROUP_/COUNTER'},\n",
       " '_LIST_OF_COUNTERS_': ['_SINGLETONS_GROUP_/COUNTER',\n",
       "  'jet/njet',\n",
       "  'muons/nmuons'],\n",
       " '_SINGLETONS_GROUP_/COUNTER': [1, 1],\n",
       " '_MAP_DATASETS_TO_DATA_TYPES_': {'_SINGLETONS_GROUP_/COUNTER': int,\n",
       "  'jet/njet': int,\n",
       "  'jet/px': numpy.int64,\n",
       "  'jet/py': numpy.int64,\n",
       "  'muons/nmuons': int,\n",
       "  'muons/px': numpy.int64,\n",
       "  'muons/py': numpy.int64,\n",
       "  'nParticles': numpy.int64},\n",
       " '_META_': {'muons': 'This is data for a subatomic particle'},\n",
       " 'jet/njet': <Array [3, 4] type='2 * int64'>,\n",
       " 'jet/px': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'jet/py': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'muons/nmuons': <Array [3, 4] type='2 * int64'>,\n",
       " 'muons/px': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'muons/py': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'nParticles': <Array [3, 4] type='2 * int64'>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.add_meta(newdata, 'muons', 'This is data for a subatomic particle')\n",
    "newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a3db7-e2db-4592-84a4-6febb128df83",
   "metadata": {},
   "source": [
    "Notice how that metadata is now stored in the `_META_` group! \n",
    "\n",
    "We can also add metadata for singletons. Let's add some to `nParticles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c91953-a072-4b10-8039-e154552ad46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_GROUPS_': {'_SINGLETONS_GROUP_': ['COUNTER', 'nParticles'],\n",
       "  'jet': ['njet', 'px', 'py'],\n",
       "  'muons': ['nmuons', 'px', 'py']},\n",
       " '_MAP_DATASETS_TO_COUNTERS_': {'_SINGLETONS_GROUP_': '_SINGLETONS_GROUP_/COUNTER',\n",
       "  'jet': 'jet/njet',\n",
       "  'jet/px': 'jet/njet',\n",
       "  'jet/py': 'jet/njet',\n",
       "  'muons': 'muons/nmuons',\n",
       "  'muons/px': 'muons/nmuons',\n",
       "  'muons/py': 'muons/nmuons',\n",
       "  'nParticles': '_SINGLETONS_GROUP_/COUNTER'},\n",
       " '_LIST_OF_COUNTERS_': ['_SINGLETONS_GROUP_/COUNTER',\n",
       "  'jet/njet',\n",
       "  'muons/nmuons'],\n",
       " '_SINGLETONS_GROUP_/COUNTER': [1, 1],\n",
       " '_MAP_DATASETS_TO_DATA_TYPES_': {'_SINGLETONS_GROUP_/COUNTER': int,\n",
       "  'jet/njet': int,\n",
       "  'jet/px': numpy.int64,\n",
       "  'jet/py': numpy.int64,\n",
       "  'muons/nmuons': int,\n",
       "  'muons/px': numpy.int64,\n",
       "  'muons/py': numpy.int64,\n",
       "  'nParticles': numpy.int64},\n",
       " '_META_': {'muons': 'This is data for a subatomic particle',\n",
       "  'nParticles': 'This is how many muons were observed in each event.'},\n",
       " 'jet/njet': <Array [3, 4] type='2 * int64'>,\n",
       " 'jet/px': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'jet/py': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'muons/nmuons': <Array [3, 4] type='2 * int64'>,\n",
       " 'muons/px': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'muons/py': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'nParticles': <Array [3, 4] type='2 * int64'>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.add_meta(newdata, 'nParticles', 'This is how many muons were observed in each event.')\n",
    "newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b6ff1-cd3f-4718-a7ec-7a754f35be90",
   "metadata": {},
   "source": [
    "Finally, we can add some units to a dataset by giving it metadata! Let's add units to all of the momentums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bddd37f-66b9-4a7e-bd83-0e3f4f8bba1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_GROUPS_': {'_SINGLETONS_GROUP_': ['COUNTER', 'nParticles'],\n",
       "  'jet': ['njet', 'px', 'py'],\n",
       "  'muons': ['nmuons', 'px', 'py']},\n",
       " '_MAP_DATASETS_TO_COUNTERS_': {'_SINGLETONS_GROUP_': '_SINGLETONS_GROUP_/COUNTER',\n",
       "  'jet': 'jet/njet',\n",
       "  'jet/px': 'jet/njet',\n",
       "  'jet/py': 'jet/njet',\n",
       "  'muons': 'muons/nmuons',\n",
       "  'muons/px': 'muons/nmuons',\n",
       "  'muons/py': 'muons/nmuons',\n",
       "  'nParticles': '_SINGLETONS_GROUP_/COUNTER'},\n",
       " '_LIST_OF_COUNTERS_': ['_SINGLETONS_GROUP_/COUNTER',\n",
       "  'jet/njet',\n",
       "  'muons/nmuons'],\n",
       " '_SINGLETONS_GROUP_/COUNTER': [1, 1],\n",
       " '_MAP_DATASETS_TO_DATA_TYPES_': {'_SINGLETONS_GROUP_/COUNTER': int,\n",
       "  'jet/njet': int,\n",
       "  'jet/px': numpy.int64,\n",
       "  'jet/py': numpy.int64,\n",
       "  'muons/nmuons': int,\n",
       "  'muons/px': numpy.int64,\n",
       "  'muons/py': numpy.int64,\n",
       "  'nParticles': numpy.int64},\n",
       " '_META_': {'muons': 'This is data for a subatomic particle',\n",
       "  'nParticles': 'This is how many muons were observed in each event.',\n",
       "  'jet/px': 'kg * m / s',\n",
       "  'jet/py': 'kg * m / s',\n",
       "  'muons/px': 'kg * m / s',\n",
       "  'muons/py': 'kg * m / s'},\n",
       " 'jet/njet': <Array [3, 4] type='2 * int64'>,\n",
       " 'jet/px': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'jet/py': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'muons/nmuons': <Array [3, 4] type='2 * int64'>,\n",
       " 'muons/px': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'muons/py': <Array [1, 2, 3, 3, 4, 6, 7] type='7 * int64'>,\n",
       " 'nParticles': <Array [3, 4] type='2 * int64'>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in ['jet/px', 'jet/py', 'muons/px', 'muons/py']: # loop over all the momentums\n",
    "    hf.add_meta(newdata, key, 'kg * m / s') # add units to each of these momentums\n",
    "newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88228f1-eacd-44aa-b3cf-f1f15bdaecf2",
   "metadata": {},
   "source": [
    "### Reading Group and Dataset Metadata\n",
    "To view the metadata, all we need to do is retrieve the `_META_` group from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddafee30-425f-49b5-811b-f44ea33bba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Metadata:\n",
      "{'muons': 'This is data for a subatomic particle', 'nParticles': 'This is how many muons were observed in each event.', 'jet/px': 'kg * m / s', 'jet/py': 'kg * m / s', 'muons/px': 'kg * m / s', 'muons/py': 'kg * m / s'}\n",
      "\n",
      "Muons Metadata:\n",
      "This is data for a subatomic particle\n"
     ]
    }
   ],
   "source": [
    "# get all the metadata\n",
    "print(f\"All Metadata:\\n{newdata['_META_']}\")\n",
    "print()\n",
    "\n",
    "# metadata of muons\n",
    "print(f\"Muons Metadata:\\n{newdata['_META_']['muons']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c764484-6815-4fd1-905e-af42c1f928e1",
   "metadata": {},
   "source": [
    "## Hepfile Headers\n",
    "While headers are not directly built in to hdf5, we add the ability to write headers for hepfiles because they can hold important information about the data in the file. Additionally, other file structures that users may want to translate to hepfiles have header information that will need to be stored in the hepfile. We allow for the use of headers by just saving the information as a set of datasets underneath a protected group name (`_HEADER_`). There are some useful functions built into the hepfile read module to help with writing and reading these protected groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecb19ca-b9aa-4a12-bab8-cf51349d309a",
   "metadata": {},
   "source": [
    "### Writing Header Information\n",
    "To add a header to a hepfile, we just need to use the `hf.write_file_header` function. This takes in a filename and a dictionary of the header information. Let's instead add the author and institution to the hepfile header as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f762ce-e885-4737-97c7-80b3fb9e75f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header data added\n"
     ]
    }
   ],
   "source": [
    "hdr = {'Author': 'Your Name',\n",
    "       'Institution': 'Siena College'}\n",
    "\n",
    "hf.write_file_header(filename, hdr);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670e102-9d2e-4965-980e-3d7377a8e7d2",
   "metadata": {},
   "source": [
    "### Reading Header Information\n",
    "To show the header, we can use `hf.print_file_header` which just takes in a filename and returns the formatted string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46750980-87c5-42bd-935f-e4b35443a6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "###                      Hepfile Header                      ###\n",
      "################################################################\n",
      "################################################################\n",
      "Author:\t\t\tYour Name\n",
      "Institution:\t\t\tSiena College\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hf.print_file_header(filename);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281fb4df-35a0-40bc-9f06-fa059d9a52d3",
   "metadata": {},
   "source": [
    "To instead return the header, we can use `hf.get_file_header` which takes in a filename and a return_type. The return_type can either be `dict`, which returns a dictionary, or `df`, which returns a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90200aa4-9480-423f-9aac-567d04ea254d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Institution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your Name</td>\n",
       "      <td>Siena College</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Author    Institution\n",
       "0  Your Name  Siena College"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = hf.get_file_header(filename, return_type='df')\n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b0177-c617-4bdb-b557-ca2c94adab53",
   "metadata": {},
   "source": [
    "### More advanced headers\n",
    "Let's say we instead have the following header from another file type, like a FITS file, that has a field, values, and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9279d35-40d6-459b-b0bd-b37f9927d1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUTHOR:\t\tYour Name / This is a comment that says this fields is the authors name\n",
      "INSTITUTION:\t\tSiena College / This is another institution\n",
      "BEAM ENERGY:\t\t13 / TeV\n",
      "BEAM TYPE:\t\tprotons / Beam Type\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fits_hdr = '''\n",
    "AUTHOR:\\t\\tYour Name / This is a comment that says this fields is the authors name\n",
    "INSTITUTION:\\t\\tSiena College / This is another institution\n",
    "BEAM ENERGY:\\t\\t13 / TeV\n",
    "BEAM TYPE:\\t\\tprotons / Beam Type\n",
    "'''\n",
    "\n",
    "print(fits_hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed65356-a84e-4c73-a7dc-8a265fe14313",
   "metadata": {},
   "source": [
    "We can then parse this header and organize it into three different datasets to be stored in the header: fields, values, and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f16fa2b-25d7-4c50-8f5c-0f400c3dba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': ['AUTHOR', 'INSTITUTION', 'BEAM ENERGY', 'BEAM TYPE'], 'values': ['Your Name', 'Siena College', '13', 'protons'], 'comments': ['This is a comment that says this fields is the authors name', 'This is another institution', 'TeV', 'Beam Type']}\n"
     ]
    }
   ],
   "source": [
    "hdr = {\n",
    "'fields' : [],\n",
    "'values' : [],\n",
    "'comments' : []\n",
    "}\n",
    "\n",
    "for line in fits_hdr.split('\\n'):\n",
    "    if len(line) == 0: continue\n",
    "    \n",
    "    hdr['fields'].append(line.split(':')[0])\n",
    "    hdr['values'].append(line.split(':')[1].split('/')[0].strip())\n",
    "    hdr['comments'].append(line.split('/')[-1].strip())\n",
    "    \n",
    "print(hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666eafce-5660-4b21-9f42-af1d501334f2",
   "metadata": {},
   "source": [
    "This is now in a workable format to pass into `hf.write_file_header`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b13bd41-7e60-4e32-a160-117a586eecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header data added\n",
      "################################################################\n",
      "###                      Hepfile Header                      ###\n",
      "################################################################\n",
      "################################################################\n",
      "comments:\t\t\tThis is a comment that says this fields is the authors name\n",
      "\t\t\tThis is another institution\n",
      "\t\t\tTeV\n",
      "\t\t\tBeam Type\n",
      "fields:\t\t\tAUTHOR\n",
      "\t\t\tINSTITUTION\n",
      "\t\t\tBEAM ENERGY\n",
      "\t\t\tBEAM TYPE\n",
      "values:\t\t\tYour Name\n",
      "\t\t\tSiena College\n",
      "\t\t\t13\n",
      "\t\t\tprotons\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hf.write_file_header(filename, hdr)\n",
    "hf.print_file_header(filename);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
