{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833f7a54-de23-42c3-9539-7f867fbfaf18",
   "metadata": {},
   "source": [
    "# Writing a hepfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fb291-9793-4f9c-a12d-84e60fe7e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from hepfile import write as writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220bb75-f076-4066-a201-d73c81af7389",
   "metadata": {},
   "source": [
    "Once hepfile.write is imported, we need to start by initializing the empty data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fffe4e-de19-4a1d-9b2c-d4da9b49b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = writer.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515cf60c-9fe5-430d-ab8a-1503ede01b21",
   "metadata": {},
   "source": [
    "Now that the empty data structure is initialized, we must set up groups and datasets. Groups hold datasets and datasets hold data about that group. You can also just create higher level datasets that are considered \"singletons\" which do not correspond to a specific group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1fd13-ce7a-44f8-a6ac-6e49b895e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the groups\n",
    "writer.create_group(data,'jet',counter='njet')\n",
    "writer.create_group(data,'muons',counter='nmuon')\n",
    "\n",
    "# add datasets to different groups\n",
    "writer.create_dataset(data,['e','px','py','pz'],group='jet',dtype=float)\n",
    "writer.create_dataset(data,['algorithm'],group='jet',dtype=int)\n",
    "writer.create_dataset(data,['words'],group='jet',dtype=str)\n",
    "writer.create_dataset(data,['e','px','py','pz'],group='muons',dtype=float)\n",
    "\n",
    "# add a higher level dataset that doesn't have a group, a \"singleton\"\n",
    "writer.create_dataset(data,['METpx','METpy'],dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90305e-33d3-42c6-bad8-76712703f63b",
   "metadata": {},
   "source": [
    "To start adding data to the groups and datasets we have to generate an empty bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a24843-e480-4df2-a4d6-e027db36bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = writer.create_single_bucket(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457380e2-d7f8-43bd-bb35-c367c8781636",
   "metadata": {},
   "source": [
    "Now that we have the hepfile structure set up, we can generate random data and insert it into the hepfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed60a79-aebc-494b-b78d-c351c2b39a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rando_words = [\"hi\", \"bye\", \"ciao\", \"aloha\"]\n",
    "\n",
    "for i in range(0,10000):\n",
    "\n",
    "    #hepfile.clear_event(event)\n",
    "\n",
    "    njet = 17\n",
    "    bucket['jet/njet'] = njet\n",
    "\n",
    "    for n in range(njet):\n",
    "        bucket['jet/e'].append(np.random.random())\n",
    "        bucket['jet/px'].append(np.random.random())\n",
    "        bucket['jet/py'].append(np.random.random())\n",
    "        bucket['jet/pz'].append(np.random.random())\n",
    "\n",
    "        bucket['jet/algorithm'].append(np.random.randint(-1,1))\n",
    "\n",
    "        bucket['jet/words'].append(np.random.choice(rando_words))\n",
    "\n",
    "    bucket['METpx'] = np.random.random()\n",
    "    bucket['METpy'] = np.random.random()\n",
    "\n",
    "    #hepfile.pack(data,event,EMPTY_OUT_BUCKET=False)\n",
    "    return_value = writer.pack(data,bucket,STRICT_CHECKING=True)\n",
    "    if return_value != 0:\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e08af-966d-4420-af65-6a5a0619cb0d",
   "metadata": {},
   "source": [
    "Finally, we are ready to write this random data to a file called `output.hdf5`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab1dbd-054c-4628-8939-65227f52dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing the file...\")\n",
    "#hdfile = hepfile.write_to_file('output.hdf5',data)\n",
    "hdfile = writer.write_to_file('output.hdf5',data,comp_type='gzip',comp_opts=9,verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
